{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33f60024",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from numba import njit, prange\n",
    "\n",
    "import xgboost as xgb\n",
    "# import lightgbm as lgb\n",
    "# import catboost as cb\n",
    "\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# import cuml\n",
    "# from cuml.explainer import TreeExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fabbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONFIG:\n",
    "    WSL = False\n",
    "    LOCAL = True\n",
    "    TRAIN = False\n",
    "\n",
    "    RANDOM_STATE = 42\n",
    "\n",
    "    DATE_COL = \"__index_level_0__\"\n",
    "    TARGET_COL = \"label\"\n",
    "\n",
    "    if LOCAL:\n",
    "        TRAIN_PATH = \"data/train.parquet\"\n",
    "        TEST_PATH = \"data/test.parquet\"\n",
    "        SUBMISSION_PATH = \"submission.csv\"\n",
    "        SHAP_PATH = \"data/shap_summary.parquet\"\n",
    "        STABILITY_PATH = \"data/feature_stability_summary.parquet\"\n",
    "    else:\n",
    "        TRAIN_PATH = \"/kaggle/input/drw-crypto-market-prediction/train.parquet\"\n",
    "        TEST_PATH = \"/kaggle/input/drw-crypto-market-prediction/test.parquet\"\n",
    "        SUBMISSION_PATH = \"/kaggle/input/drw-crypto-market-prediction/submission.csv\"\n",
    "        SHAP_PATH = \"/kaggle/input/drw-crypto-market-prediction/shap_summary.parquet\"\n",
    "        STABILITY_PATH = \"/kaggle/input/drw-crypto-market-prediction/feature_stability_summary.parquet\"\n",
    "\n",
    "    if WSL:\n",
    "        mount = \"/mnt/\"\n",
    "        TRAIN_PATH = f\"{mount}c/Users/Admin/Desktop/Personal-Projects/Kaggle/DRW - Crypto Market Prediction/{TRAIN_PATH}\"\n",
    "        TEST_PATH = f\"{mount}c/Users/Admin/Desktop/Personal-Projects/Kaggle/DRW - Crypto Market Prediction/{TEST_PATH}\"\n",
    "        SUBMISSION_PATH = f\"{mount}c/Users/Admin/Desktop/Personal-Projects/Kaggle/DRW - Crypto Market Prediction/{SUBMISSION_PATH}\"\n",
    "        SHAP_PATH = f\"{mount}c/Users/Admin/Desktop/Personal-Projects/Kaggle/DRW - Crypto Market Prediction/{SHAP_PATH}\"\n",
    "        STABILITY_PATH = f\"{mount}c/Users/Admin/Desktop/Personal-Projects/Kaggle/DRW - Crypto Market Prediction/{STABILITY_PATH}\"\n",
    "\n",
    "    CORE_FEATURES = [\n",
    "        \"X363\",\n",
    "        \"X321\",\n",
    "        \"X405\",\n",
    "        \"X730\",\n",
    "        \"X523\",\n",
    "        \"X756\",\n",
    "        \"X589\",\n",
    "        \"X462\",\n",
    "        \"X779\",\n",
    "        \"X25\",\n",
    "        \"X532\",\n",
    "        \"X520\",\n",
    "        \"X329\",\n",
    "        \"X383\",\n",
    "        \"X752\",\n",
    "        \"X287\",\n",
    "        \"X298\",\n",
    "        \"X759\",\n",
    "        \"X302\",\n",
    "        \"X55\",\n",
    "        \"X56\",\n",
    "        \"X52\",\n",
    "        \"X303\",\n",
    "        \"X51\",\n",
    "        \"X598\",\n",
    "        \"X385\",\n",
    "        \"X603\",\n",
    "        \"X674\",\n",
    "        \"X415\",\n",
    "        \"X345\",\n",
    "        \"X174\",\n",
    "        \"X178\",\n",
    "        \"X168\",\n",
    "        \"X612\",\n",
    "        \"bid_qty\",\n",
    "        \"ask_qty\",\n",
    "        \"buy_qty\",\n",
    "        \"sell_qty\",\n",
    "        \"volume\",\n",
    "    ]\n",
    "\n",
    "    KNOWN_FEATURES = [\n",
    "        \"bid_qty\",\n",
    "        \"ask_qty\",\n",
    "        \"buy_qty\",\n",
    "        \"sell_qty\",\n",
    "        \"volume\",\n",
    "    ]\n",
    "\n",
    "    ANONYMOUS_FEATURES = [f\"X{i}\" for i in range(1, 781)]\n",
    "    OG_FEATURES = ANONYMOUS_FEATURES + KNOWN_FEATURES\n",
    "\n",
    "    # BID-ASK QUANTITY FEATURES\n",
    "    BID_ASK_QTY_FEATURES = [\"bid_ask_qty_ratio\", \"bid_ask_qty_spread\"]\n",
    "\n",
    "    # BUY-SELL QUANTITY FEATURES\n",
    "    BUY_SELL_QTY_FEATURES = [\"buy_sell_qty_ratio\", \"buy_sell_qty_spread\"]\n",
    "\n",
    "    # VOLUME FEATURES\n",
    "    VOLUME_FEATURES = [\n",
    "        \"bid_ask_volume\",\n",
    "        \"buy_sell_volume\",\n",
    "        \"bid_ask_to_volume_ratio\",\n",
    "        \"buy_sell_to_volume_ratio\",\n",
    "    ]\n",
    "\n",
    "    # CROSS FEATURES\n",
    "    CROSS_FEATURES = [\"bid_ask_to_buy_sell_qty_ratio\", \"buy_sell_imbalance\"]\n",
    "\n",
    "    # BID-ASK FEATURES\n",
    "    BID_ASK_FEATURES = [\n",
    "        \"bid_ask_spread\",\n",
    "        \"bid_ask_ratio\",\n",
    "        \"buy_sell_ratio\",\n",
    "        \"order_flow_imbalance\",\n",
    "    ]\n",
    "\n",
    "    # PRESSURE INDICATORS\n",
    "    PRESSURE_INDICATORS = [\"buying_pressure\", \"selling_pressure\", \"net_pressure\"]\n",
    "\n",
    "    # LIQUIDITY FEATURES\n",
    "    LIQUIDITY_FEATURES = [\"total_liquidity\", \"liquidity_imbalance\", \"liquidity_ratio\"]\n",
    "\n",
    "    # MARKET MICROSTRUCTURE FEATURES\n",
    "    MARKET_MICROSTRUCTURE_FEATURES = [\"kyle_lambda\", \"vpin\"]\n",
    "\n",
    "    # ADDITIONAL FEATURES\n",
    "    ADDITIONAL_FEATURES = [\n",
    "        \"effective_spread\",\n",
    "        \"realized_spread\",\n",
    "        \"price_impact\",\n",
    "        \"trade_intensity\",\n",
    "    ]\n",
    "\n",
    "    if not TRAIN:\n",
    "        stability = pl.read_parquet(STABILITY_PATH)\n",
    "        shap = pl.read_parquet(SHAP_PATH)\n",
    "\n",
    "        stability = stability.filter(pl.col(\"sum\") > 0).sort(pl.col(\"sum\"), descending=True)\n",
    "\n",
    "        stability = stability.sort(pl.col(\"sum\"), descending=True)\n",
    "\n",
    "        shap_rank = shap.transpose(include_header=True).with_columns(pl.all().exclude(\"column\").rank(\"ordinal\", descending=True))\n",
    "        shap_rank = pl.concat(\n",
    "            [\n",
    "                shap_rank.select(\"column\"),\n",
    "                pl.DataFrame(shap_rank.select(pl.all().exclude(\"column\")).to_numpy().mean(axis=1)).rename({\"column_0\": \"mean_rank\"}),\n",
    "                pl.DataFrame(shap_rank.select(pl.all().exclude(\"column\")).to_numpy().std(axis=1)).rename({\"column_0\": \"std_rank\"}),\n",
    "            ],\n",
    "            how=\"horizontal\",\n",
    "        )\n",
    "\n",
    "        shap_rank = shap_rank.sort(by=\"mean_rank\", descending=False)\n",
    "\n",
    "        EVAL_CORE_FEATURES = CORE_FEATURES\n",
    "\n",
    "    FEATURE_SELECTION_SAMPLE_SIZE = 750000\n",
    "    TARGET_FEATURES = 120\n",
    "    COMBINED_SCORES = None\n",
    "\n",
    "    CLIP_PERCENTILE, CLIP_LOWER, CLIP_UPPER = 99, 0, 0\n",
    "\n",
    "    XGB_PARAMS = {\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"device\": \"gpu\",\n",
    "        \"colsample_bylevel\": 0.4778,\n",
    "        \"colsample_bynode\": 0.3628,\n",
    "        \"colsample_bytree\": 0.7107,\n",
    "        \"gamma\": 1.7095,\n",
    "        \"learning_rate\": 0.02213,\n",
    "        \"max_depth\": 20,\n",
    "        \"max_leaves\": 12,\n",
    "        \"min_child_weight\": 16,\n",
    "        \"n_estimators\": 1667,\n",
    "        \"subsample\": 0.06567,\n",
    "        \"reg_alpha\": 39.3524,\n",
    "        \"reg_lambda\": 75.4484,\n",
    "        \"verbosity\": 0,\n",
    "        \"random_state\": RANDOM_STATE,\n",
    "        \"early_stopping_rounds\": 100,\n",
    "        \"n_jobs\": -1,\n",
    "    }\n",
    "\n",
    "    N_FOLDS = 5\n",
    "\n",
    "    MODELS = [\n",
    "        {\"name\": \"xgb\", \"Estimator\": xgb.XGBRegressor, \"params\": XGB_PARAMS},\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77ca424",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardScalerWrapper:\n",
    "    def __init__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.columns_ = None\n",
    "\n",
    "    def fit(self, df: pl.DataFrame):\n",
    "        X = df.to_numpy()\n",
    "        self.scaler.fit(X)\n",
    "        self.columns_ = df.columns\n",
    "        return self\n",
    "\n",
    "    def transform(self, df: pl.DataFrame) -> pl.DataFrame:\n",
    "        X = df.to_numpy()\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        return pl.DataFrame(X_scaled, schema=self.columns_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedd4182",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FEATURE_SELECTION:\n",
    "    def __init__(self, x, y) -> None:\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def smart_feature_selection(self, sample_size=500_000, top_k=150):\n",
    "        \"\"\"\n",
    "        Efficient feature selection using recent data samples\n",
    "        Uses multiple methods and focuses on recent crypto patterns\n",
    "        \"\"\"\n",
    "        print(f\"Starting smart feature selection with {len(self.x)} samples...\")\n",
    "\n",
    "        # Use the most recent data for feature selection (crypto patterns change)\n",
    "        recent_sample_size = min(sample_size, len(self.x))\n",
    "        recent_df = self.x.tail(recent_sample_size).copy()\n",
    "        print(f\"Using {len(recent_df)} recent samples for feature selection\")\n",
    "\n",
    "        # Get all feature columns (excluding label)\n",
    "        feature_cols = [col for col in recent_df.columns if col != CONFIG.TARGET_COL]\n",
    "        print(f\"Total features before selection: {len(feature_cols)}\")\n",
    "\n",
    "        X_sample = recent_df[feature_cols]\n",
    "        y_sample = self.y.tail(recent_sample_size).copy()\n",
    "\n",
    "        # Remove features with zero variance or too many missing values\n",
    "        print(\"Removing low-variance and high-missing features...\")\n",
    "        valid_features = []\n",
    "        for col in feature_cols:\n",
    "            if X_sample[col].var() > 1e-8 and X_sample[col].isna().sum() / len(X_sample) < 0.95:\n",
    "                valid_features.append(col)\n",
    "\n",
    "        X_sample = X_sample[valid_features]\n",
    "        print(f\"Features after variance/missing filter: {len(valid_features)}\")\n",
    "\n",
    "        # Method 1: Correlation with target (fast)\n",
    "        print(\"Computing correlations...\")\n",
    "        correlations = {}\n",
    "        for col in valid_features:\n",
    "            try:\n",
    "                corr = np.abs(pearsonr(X_sample[col], y_sample)[0])\n",
    "                if not np.isnan(corr):\n",
    "                    correlations[col] = corr\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        # Method 2: Mutual Information (sample for speed)\n",
    "        print(\"Computing mutual information...\")\n",
    "        mi_sample_size = min(100_000, len(X_sample))\n",
    "        sample_idx = np.random.choice(\n",
    "            len(X_sample),\n",
    "            mi_sample_size,\n",
    "            replace=False,\n",
    "        )\n",
    "        X_mi = X_sample.iloc[sample_idx]\n",
    "        y_mi = y_sample.iloc[sample_idx]\n",
    "\n",
    "        try:\n",
    "            mi_scores = mutual_info_regression(X_mi, y_mi, random_state=CONFIG.RANDOM_STATE, n_jobs=-1)\n",
    "            mi_dict = dict(zip(X_mi.columns, mi_scores))\n",
    "        except:\n",
    "            mi_dict = {}\n",
    "\n",
    "        # Method 3: L1 regularization feature importance (fast)\n",
    "        print(\"Computing L1 regularization scores...\")\n",
    "        try:\n",
    "            scaler = StandardScaler()\n",
    "            X_scaled = scaler.fit_transform(X_mi)\n",
    "            lasso = LassoCV(cv=CONFIG.N_FOLDS, random_state=CONFIG.RANDOM_STATE, max_iter=1000)\n",
    "            lasso.fit(X_scaled, y_mi)\n",
    "            l1_scores = abs(lasso.coef_)\n",
    "            l1_dict = dict(zip(X_mi.columns, l1_scores))\n",
    "        except:\n",
    "            l1_dict = {}\n",
    "\n",
    "        # Method 4: Tree-based importance (sample for speed)\n",
    "        print(\"Computing tree-based importance...\")\n",
    "        stab = CONFIG.stability.select([\"column\", \"sum\"]).to_pandas().set_index(\"column\").to_dict()[\"sum\"]\n",
    "        shap = CONFIG.shap_rank.select([\"column\", \"mean_rank\"]).to_pandas().set_index(\"column\").to_dict()[\"mean_rank\"]\n",
    "\n",
    "        # Combine scores with weights\n",
    "        print(\"Combining feature scores...\")\n",
    "        combined_scores = {}\n",
    "        for col in valid_features:\n",
    "            score = 0\n",
    "            score += correlations.get(col, 0) * 0.3  # Correlation weight\n",
    "            score += mi_dict.get(col, 0) * 0.25  # MI weight\n",
    "            score += l1_dict.get(col, 0) * 0.25  # L1 weight\n",
    "            score += stab.get(col, 0) * 0.1  # stab weight\n",
    "            score += shap.get(col, 0) * 0.1  # stab weight\n",
    "            combined_scores[col] = score\n",
    "\n",
    "        # Select top features\n",
    "        selected_features = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        final_features = [feat[0] for feat in selected_features[:top_k] if feat[1] >= 50]\n",
    "\n",
    "        print(f\"Selected {len(final_features)} features\")\n",
    "        print(\"Top 10 selected features:\")\n",
    "        for i, (feat, score) in enumerate(selected_features[:10]):\n",
    "            print(f\"  {i + 1:2d}. {feat:30s} - Score: {score:.4f}\")\n",
    "\n",
    "        CONFIG.EVAL_CORE_FEATURES += final_features\n",
    "\n",
    "        return combined_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d878381",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureEngineering:\n",
    "    def __init__(self, df, data_set=\"train\"):\n",
    "        self.df = df\n",
    "        self.data_set = data_set\n",
    "\n",
    "        self.scaler = StandardScalerWrapper()\n",
    "\n",
    "    def handle_inf_nan(self, df):\n",
    "        df = df.with_columns(\n",
    "            pl.when(pl.col(col).is_infinite()).then(0.0).otherwise(pl.col(col)).alias(col)\n",
    "            for col in df.collect_schema().names()\n",
    "            if col not in [CONFIG.DATE_COL, CONFIG.TARGET_COL]\n",
    "        )\n",
    "        df = df.fill_null(0).fill_nan(0)\n",
    "        return df\n",
    "\n",
    "    def feature_engineering(self, df):\n",
    "        return df.with_columns(\n",
    "            # Bid-Ask Quantity Features\n",
    "            bid_ask_qty_ratio=pl.col(\"bid_qty\") / pl.col(\"ask_qty\"),\n",
    "            log_bid_qty=pl.col(\"bid_qty\").log(),\n",
    "            log_ask_qty=pl.col(\"ask_qty\").log(),\n",
    "            bid_ask_qty_spread=(pl.col(\"bid_qty\") - pl.col(\"ask_qty\")),\n",
    "            # Buy-Sell Quantity Features\n",
    "            buy_sell_qty_ratio=(pl.col(\"buy_qty\") / pl.col(\"sell_qty\")),\n",
    "            log_buy_qty=pl.col(\"buy_qty\").log(),\n",
    "            log_sell_qty=pl.col(\"sell_qty\").log(),\n",
    "            buy_sell_qty_spread=(pl.col(\"buy_qty\") - pl.col(\"sell_qty\")),\n",
    "            # Volume Features\n",
    "            bid_ask_volume=(pl.col(\"bid_qty\") + pl.col(\"ask_qty\")),\n",
    "            buy_sell_volume=(pl.col(\"buy_qty\") + pl.col(\"sell_qty\")),\n",
    "            bid_ask_to_volume_ratio=((pl.col(\"bid_qty\") + pl.col(\"ask_qty\")) / pl.col(\"volume\")),\n",
    "            buy_sell_to_volume_ratio=((pl.col(\"buy_qty\") + pl.col(\"sell_qty\")) / pl.col(\"volume\")),\n",
    "            # Cross Features\n",
    "            bid_ask_to_buy_sell_qty_ratio=((pl.col(\"bid_qty\") + pl.col(\"ask_qty\")) / (pl.col(\"buy_qty\") + pl.col(\"sell_qty\"))),\n",
    "            buy_sell_imbalance=((pl.col(\"buy_qty\") - pl.col(\"sell_qty\")) / (pl.col(\"buy_qty\") + pl.col(\"sell_qty\"))),\n",
    "            # Bid-Ask Features\n",
    "            bid_ask_spread=(pl.col(\"ask_qty\") - pl.col(\"bid_qty\")),\n",
    "            bid_ask_ratio=(pl.col(\"bid_qty\") / (pl.col(\"ask_qty\") + 1e-8)),\n",
    "            buy_sell_ratio=(pl.col(\"buy_qty\") / (pl.col(\"sell_qty\") + 1e-8)),\n",
    "            order_flow_imbalance=((pl.col(\"buy_qty\") - pl.col(\"sell_qty\")) / (pl.col(\"volume\") + 1e-8)),\n",
    "            # Pressure Indicators\n",
    "            buying_pressure=(pl.col(\"buy_qty\") / (pl.col(\"volume\") + 1e-8)),\n",
    "            selling_pressure=(pl.col(\"sell_qty\") / (pl.col(\"volume\") + 1e-8)),\n",
    "            net_pressure=((pl.col(\"buy_qty\") - pl.col(\"sell_qty\")) / (pl.col(\"volume\") + 1e-8)),\n",
    "            # Liquidity Features\n",
    "            total_liquidity=(pl.col(\"bid_qty\") + pl.col(\"ask_qty\")),\n",
    "            liquidity_imbalance=((pl.col(\"bid_qty\") - pl.col(\"ask_qty\")) / (pl.col(\"bid_qty\") + pl.col(\"ask_qty\") + 1e-8)),\n",
    "            liquidity_ratio=((pl.col(\"bid_qty\") + pl.col(\"ask_qty\")) / (pl.col(\"volume\") + 1e-8)),\n",
    "            # Volume Transformations\n",
    "            log_volume=pl.col(\"volume\").log1p(),\n",
    "            sqrt_volume=pl.col(\"volume\").sqrt(),\n",
    "            # Market Microstructure\n",
    "            kyle_lambda=((pl.col(\"buy_qty\") - pl.col(\"sell_qty\")) / (pl.col(\"volume\") + 1e-8) / (pl.col(\"volume\").sqrt() + 1e-8)),\n",
    "            vpin=(pl.col(\"buy_qty\") - pl.col(\"sell_qty\")).abs() / (pl.col(\"buy_qty\") + pl.col(\"sell_qty\") + 1e-8),\n",
    "            # Additional Features\n",
    "            effective_spread=(\n",
    "                2 * ((pl.col(\"buy_qty\") - pl.col(\"sell_qty\")) / (pl.col(\"volume\") + 1e-8)).abs() * (pl.col(\"ask_qty\") - pl.col(\"bid_qty\"))\n",
    "            ),\n",
    "            realized_spread=(\n",
    "                (pl.col(\"ask_qty\") - pl.col(\"bid_qty\"))\n",
    "                * ((pl.col(\"buy_qty\") - pl.col(\"sell_qty\")).abs() / (pl.col(\"buy_qty\") + pl.col(\"sell_qty\") + 1e-8))\n",
    "            ),\n",
    "            price_impact=(\n",
    "                ((pl.col(\"buy_qty\") - pl.col(\"sell_qty\")) / (pl.col(\"volume\") + 1e-8)) / (pl.col(\"volume\").sqrt() + 1e-8) * pl.col(\"volume\")\n",
    "            ),\n",
    "            trade_intensity=(pl.col(\"volume\") / ((pl.col(\"bid_qty\") + pl.col(\"ask_qty\")) + 1e-8)),\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    @njit(parallel=True)\n",
    "    def compute_triplet_imbalance(df_values, comb_indices):\n",
    "        num_rows = df_values.shape[0]\n",
    "        num_combinations = len(comb_indices)\n",
    "        imbalance_features = np.empty((num_rows, num_combinations))\n",
    "\n",
    "        for i in prange(num_combinations):\n",
    "            a, b, c = comb_indices[i]\n",
    "            for j in range(num_rows):\n",
    "                max_val = max(df_values[j, a], df_values[j, b], df_values[j, c])\n",
    "                min_val = min(df_values[j, a], df_values[j, b], df_values[j, c])\n",
    "                mid_val = df_values[j, a] + df_values[j, b] + df_values[j, c] - min_val - max_val\n",
    "\n",
    "                if mid_val == min_val:\n",
    "                    imbalance_features[j, i] = np.nan\n",
    "                else:\n",
    "                    imbalance_features[j, i] = (max_val - mid_val) / (mid_val - min_val)\n",
    "\n",
    "        return imbalance_features\n",
    "\n",
    "    # --- Step 2: Adapter function using Polars ---\n",
    "    def calculate_triplet_imbalance_numba(self, price, df: pl.DataFrame) -> pl.DataFrame:\n",
    "        df_values = df.select(price).to_numpy()\n",
    "        comb_indices = [(price.index(a), price.index(b), price.index(c)) for a, b, c in combinations(price, 3)]\n",
    "\n",
    "        features_array = self.compute_triplet_imbalance(df_values, comb_indices)\n",
    "        columns = [f\"{a}_{b}_{c}_imb2\" for a, b, c in combinations(price, 3)]\n",
    "\n",
    "        return pl.DataFrame(features_array, schema=columns)\n",
    "\n",
    "    # --- Step 3: Main feature generator ---\n",
    "    def generate_imb_features(self, train: pl.DataFrame) -> pl.DataFrame:\n",
    "        feat = (\n",
    "            [CONFIG.KNOWN_FEATURES]\n",
    "            + [CONFIG.BID_ASK_QTY_FEATURES]\n",
    "            + [CONFIG.BUY_SELL_QTY_FEATURES]\n",
    "            + [CONFIG.VOLUME_FEATURES]\n",
    "            + [CONFIG.CROSS_FEATURES]\n",
    "            + [CONFIG.BID_ASK_FEATURES]\n",
    "            + [CONFIG.PRESSURE_INDICATORS]\n",
    "            + [CONFIG.LIQUIDITY_FEATURES]\n",
    "            + [CONFIG.MARKET_MICROSTRUCTURE_FEATURES]\n",
    "            + [CONFIG.ADDITIONAL_FEATURES]\n",
    "        )\n",
    "\n",
    "        for groups in feat:\n",
    "            # 2-wise combinations\n",
    "            for a, b in combinations(groups, 2):\n",
    "                train = train.with_columns(((pl.col(a) - pl.col(b)) / (pl.col(a) + pl.col(b))).alias(f\"{a}_{b}_imb\"))\n",
    "                sum_a = train[a].sum()\n",
    "                sum_b = train[b].sum()\n",
    "                train = train.with_columns(((pl.col(a) / sum_a) / (pl.col(b) / sum_b)).alias(f\"{a}_{b}_imb3\"))\n",
    "\n",
    "            # 3-wise combinations\n",
    "            if len(groups) > 2:\n",
    "                triplet_feature = self.calculate_triplet_imbalance_numba(groups, train)\n",
    "                train = train.hstack(triplet_feature)\n",
    "\n",
    "            train = train.with_columns(*[pl.col(col).cast(pl.Float32) if train[col].dtype == pl.Float64 else pl.col(col) for col in train.columns])\n",
    "\n",
    "        return train\n",
    "\n",
    "    def add_statistical_features(self, df):\n",
    "        \"\"\"\n",
    "        Adds statistical aggregation features across all 'X'-prefixed columns:\n",
    "        - Mean\n",
    "        - Std Dev\n",
    "        - Range (max - min)\n",
    "        - Median\n",
    "        - 25th percentile\n",
    "        - 75th percentile\n",
    "        - Count of values above row mean\n",
    "        - Index of max and min column (numeric suffix)\n",
    "        - Cleans up NaNs and infs\n",
    "        \"\"\"\n",
    "\n",
    "        x_data = df.select(CONFIG.ANONYMOUS_FEATURES).to_numpy()\n",
    "\n",
    "        # Core stats (Mean, Std, Range, Median, Percentiles)\n",
    "        x_stat_mean = x_data.mean(axis=1)\n",
    "        x_stat_std = x_data.std(axis=1)\n",
    "        x_stat_range = x_data.max(axis=1) - x_data.min(axis=1)\n",
    "        x_stat_median = np.median(x_data, axis=1)\n",
    "        x_stat_p25 = np.percentile(x_data, 25, axis=1)\n",
    "        x_stat_p75 = np.percentile(x_data, 75, axis=1)\n",
    "\n",
    "        # Count of values above row mean (row-wise comparison)\n",
    "        row_means = x_stat_mean\n",
    "        x_stat_above_mean_count = (x_data > row_means.reshape(-1, 1)).sum(axis=1)\n",
    "\n",
    "        # Index (suffix) of max and min column\n",
    "        x_stat_idx_max = x_data.argmax(axis=1)\n",
    "        x_stat_idx_min = x_data.argmin(axis=1)\n",
    "\n",
    "        # Create new columns in DataFrame\n",
    "        df = df.with_columns(\n",
    "            pl.Series(name=\"x_stat_mean\", values=x_stat_mean),\n",
    "            pl.Series(name=\"x_stat_std\", values=x_stat_std),\n",
    "            pl.Series(name=\"x_stat_range\", values=x_stat_range),\n",
    "            pl.Series(name=\"x_stat_median\", values=x_stat_median),\n",
    "            pl.Series(name=\"x_stat_p25\", values=x_stat_p25),\n",
    "            pl.Series(name=\"x_stat_p75\", values=x_stat_p75),\n",
    "            pl.Series(name=\"x_stat_above_mean_count\", values=x_stat_above_mean_count),\n",
    "            pl.Series(name=\"x_stat_idx_max\", values=x_stat_idx_max),\n",
    "            pl.Series(name=\"x_stat_idx_min\", values=x_stat_idx_min),\n",
    "        )\n",
    "\n",
    "        return df\n",
    "\n",
    "    def select_core_features(self, y=None):\n",
    "        core_features_df = self.df.select(CONFIG.OG_FEATURES).collect()\n",
    "        df = self.feature_engineering(self.df)\n",
    "        df = self.generate_imb_features(df.collect())\n",
    "        df = self.add_statistical_features(df)\n",
    "        df = self.handle_inf_nan(df)\n",
    "\n",
    "        df = pl.concat([core_features_df, df.drop(CONFIG.OG_FEATURES)], how=\"horizontal\").with_columns(pl.all().shrink_dtype())\n",
    "\n",
    "        if not CONFIG.TRAIN:\n",
    "            if self.data_set == \"train\":\n",
    "                feature_selection = FEATURE_SELECTION(x=df.to_pandas(), y=y)\n",
    "                CONFIG.COMBINED_SCORES = feature_selection.smart_feature_selection(\n",
    "                    sample_size=CONFIG.FEATURE_SELECTION_SAMPLE_SIZE,\n",
    "                    top_k=CONFIG.TARGET_FEATURES,\n",
    "                )\n",
    "            df = df.select(set(CONFIG.EVAL_CORE_FEATURES))\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41e4034",
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_loader:\n",
    "    def __init__(self):\n",
    "        self.train = pl.scan_parquet(CONFIG.TRAIN_PATH).with_columns(pl.all().shrink_dtype()).drop(CONFIG.DATE_COL)\n",
    "\n",
    "        self.test = pl.scan_parquet(CONFIG.TEST_PATH).with_columns(pl.all().shrink_dtype()).drop(CONFIG.TARGET_COL)\n",
    "\n",
    "        self.train_y = self.train.select(CONFIG.TARGET_COL).collect()\n",
    "\n",
    "        CONFIG.CLIP_UPPER = np.percentile(  # type: ignore\n",
    "            self.train_y.to_numpy().flatten(), CONFIG.CLIP_PERCENTILE\n",
    "        )\n",
    "        CONFIG.CLIP_LOWER = np.percentile(  # type: ignore\n",
    "            self.train_y.to_numpy().flatten(), 100 - CONFIG.CLIP_PERCENTILE\n",
    "        )\n",
    "\n",
    "        eng = FeatureEngineering(self.train.drop(CONFIG.TARGET_COL), data_set=\"train\")\n",
    "        self.train_X = eng.select_core_features(y=self.train_y.to_pandas())\n",
    "\n",
    "        print(\"Train data loaded with shape:\", self.train_X.shape)\n",
    "\n",
    "        eng.df = self.test\n",
    "        eng.data_set = \"test\"\n",
    "        self.test_X = eng.select_core_features()\n",
    "\n",
    "        print(\"Test data loaded with shape:\", self.test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cc73bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FEATURE_STABILITY:\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_X: pl.DataFrame,\n",
    "        train_y: pl.DataFrame,\n",
    "        num_runs=5,\n",
    "        importance_type=\"gain\",\n",
    "    ):\n",
    "        self.feature_stability = {}\n",
    "        self.train_X = train_X.to_pandas()\n",
    "        self.train_y = train_y.to_pandas()\n",
    "        self.num_runs = num_runs\n",
    "        self.importance_type = importance_type\n",
    "\n",
    "        self.feature_names = train_X.columns\n",
    "        self.shap_df = pl.DataFrame()\n",
    "\n",
    "    def compute_shap(self, model, x):\n",
    "        explainers = TreeExplainer(model=model)\n",
    "        shap_values = explainers.shap_values(x)\n",
    "        shap_df = pl.DataFrame(np.abs(shap_values.get()), schema=self.feature_names).mean()\n",
    "        self.shap_df = pl.concat(\n",
    "            [self.shap_df, shap_df],\n",
    "            how=\"vertical\",\n",
    "        ).with_columns(pl.all().shrink_dtype())\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "    ):\n",
    "        importances_list = []\n",
    "\n",
    "        params = {\n",
    "            \"n_estimators\": 100,\n",
    "            \"max_depth\": 6,\n",
    "            \"learning_rate\": 0.1,\n",
    "            \"subsample\": 0.8,\n",
    "            \"colsample_bytree\": 0.8,\n",
    "            \"random_state\": CONFIG.RANDOM_STATE,\n",
    "            \"device\": \"gpu\",\n",
    "            \"verbosity\": 0,\n",
    "        }\n",
    "\n",
    "        model = xgb.XGBRegressor(**params)\n",
    "\n",
    "        for run in range(self.num_runs):\n",
    "            rs = CONFIG.RANDOM_STATE + run  # different seed for each run\n",
    "            kf = KFold(n_splits=CONFIG.N_FOLDS, shuffle=True, random_state=rs)\n",
    "            for fold, (train_idx, valid_idx) in enumerate(kf.split(self.train_X), start=1):\n",
    "                print(f\"\\n--- Fold {fold}/{CONFIG.N_FOLDS} ---\")\n",
    "                X_train = self.train_X.iloc[train_idx, :]\n",
    "                y_train = self.train_y.iloc[train_idx, :]\n",
    "\n",
    "                X_valid = self.train_X.iloc[valid_idx, :]\n",
    "                y_valid = self.train_y.iloc[valid_idx, :]\n",
    "\n",
    "                model = xgb.XGBRegressor(**params)\n",
    "\n",
    "                model.fit(\n",
    "                    X_train,\n",
    "                    y_train,\n",
    "                    eval_set=[(X_valid, y_valid)],\n",
    "                    verbose=False,\n",
    "                )\n",
    "\n",
    "                raw_score = model.get_booster().get_score(importance_type=self.importance_type)\n",
    "                importance_dict = {f: raw_score.get(f, 0.0) for f in self.feature_names}\n",
    "                importances_list.append(importance_dict)\n",
    "                self.compute_shap(model, X_train)\n",
    "\n",
    "                del model, X_train, X_valid, y_train, y_valid\n",
    "\n",
    "        self.runs = pl.DataFrame(importances_list)\n",
    "        runs_t = self.runs.transpose(include_header=True)\n",
    "        self.summary_table = pl.concat(\n",
    "            [\n",
    "                self.runs.mean().transpose(include_header=True).rename({\"column_0\": \"mean\"}),\n",
    "                self.runs.std().transpose(include_header=True).rename({\"column_0\": \"std\"}).drop(\"column\"),\n",
    "                runs_t.with_columns(*[pl.col(col) / pl.col(col).sum() for col in runs_t.columns[1:]])\n",
    "                .drop(\"column\")\n",
    "                .sum_horizontal()\n",
    "                .to_frame()\n",
    "                .with_columns(pl.all() / pl.all().sum()),\n",
    "            ],\n",
    "            how=\"horizontal\",\n",
    "        )\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5503bdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class evaluate:\n",
    "    def __init__(\n",
    "        self,\n",
    "    ):\n",
    "        pass\n",
    "\n",
    "    def get_model_slices(self, n_samples: int):\n",
    "        return [\n",
    "            {\"name\": \"full_data\", \"cutoff\": 0},\n",
    "            {\n",
    "                \"name\": \"recent_95pct\",\n",
    "                \"cutoff\": int(0.05 * n_samples),\n",
    "            },  # Most recent 95%\n",
    "            {\n",
    "                \"name\": \"recent_90pct\",\n",
    "                \"cutoff\": int(0.10 * n_samples),\n",
    "            },  # Most recent 90%\n",
    "            {\n",
    "                \"name\": \"recent_85pct\",\n",
    "                \"cutoff\": int(0.15 * n_samples),\n",
    "            },  # Most recent 85%\n",
    "            {\n",
    "                \"name\": \"recent_80pct\",\n",
    "                \"cutoff\": int(0.20 * n_samples),\n",
    "            },  # Most recent 80%\n",
    "        ]\n",
    "\n",
    "    def create_time_decay_weights(self, n: int, decay: float = 0.95) -> np.ndarray:\n",
    "        positions = np.arange(n)\n",
    "        normalized = positions / (n - 1)\n",
    "        weights = decay ** (1.0 - normalized)\n",
    "        return weights * n / weights.sum()\n",
    "\n",
    "    def adjust_weights_for_outliers(self, X, y, base_weights, outlier_fraction=0.001):\n",
    "        # Train quick model to estimate residuals\n",
    "        model = xgb.XGBRegressor(\n",
    "            n_estimators=50,\n",
    "            max_depth=10,\n",
    "            random_state=CONFIG.RANDOM_STATE,\n",
    "            device=\"gpu\",\n",
    "        )\n",
    "        model.fit(X, y, sample_weight=base_weights)\n",
    "        preds = model.predict(X)\n",
    "        residuals = np.abs(y - preds)\n",
    "\n",
    "        # Top N residuals = outliers\n",
    "        n_outliers = max(1, int(outlier_fraction * len(residuals)))\n",
    "        threshold = np.partition(residuals, -n_outliers)[-n_outliers]\n",
    "        outlier_mask = residuals >= threshold\n",
    "\n",
    "        # Downweight outliers (linear scale: 0.2â€“0.8 of base weight)\n",
    "        adjusted_weights = base_weights.copy()\n",
    "        if outlier_mask.any():\n",
    "            res_out = residuals[outlier_mask]\n",
    "            res_norm = (res_out - np.min(res_out)) / (np.ptp(res_out) + 1e-8)\n",
    "            weight_factors = 0.8 - 0.6 * res_norm\n",
    "            adjusted_weights[outlier_mask] *= weight_factors\n",
    "\n",
    "        return adjusted_weights\n",
    "\n",
    "    def train_and_evaluate(self, train_X, train_y, test_X):\n",
    "        train_X = train_X.to_numpy()\n",
    "        train_y = train_y.to_numpy().flatten()\n",
    "\n",
    "        test_X = test_X.to_numpy()\n",
    "        n_samples = train_X.shape[0]\n",
    "\n",
    "        model_slices = self.get_model_slices(n_samples)\n",
    "\n",
    "        oof_preds = {learner[\"name\"]: {s[\"name\"]: np.zeros(n_samples) for s in model_slices} for learner in CONFIG.MODELS}\n",
    "        test_preds = {learner[\"name\"]: {s[\"name\"]: np.zeros(test_X.shape[0]) for s in model_slices} for learner in CONFIG.MODELS}\n",
    "\n",
    "        full_weights = self.create_time_decay_weights(n_samples)\n",
    "        kf = KFold(n_splits=CONFIG.N_FOLDS, shuffle=False)\n",
    "\n",
    "        for fold, (train_idx, valid_idx) in enumerate(kf.split(train_X), start=1):\n",
    "            print(f\"\\n--- Fold {fold}/{CONFIG.N_FOLDS} ---\")\n",
    "            X_valid = train_X[valid_idx]\n",
    "            y_valid = train_y[valid_idx]\n",
    "\n",
    "            for s in model_slices:\n",
    "                cutoff = s[\"cutoff\"]\n",
    "                slice_name = s[\"name\"]\n",
    "                subset_x = train_X[cutoff:]\n",
    "                subset_y = train_y[cutoff:]\n",
    "                rel_idx = train_idx[train_idx >= cutoff] - cutoff\n",
    "\n",
    "                X_train = subset_x[rel_idx]\n",
    "                y_train = subset_y[rel_idx]\n",
    "                sw = self.create_time_decay_weights(len(subset_x))[rel_idx] if cutoff > 0 else full_weights[train_idx]\n",
    "\n",
    "                sw = self.adjust_weights_for_outliers(X_train, y_train, sw, outlier_fraction=0.001)\n",
    "\n",
    "                print(f\"  Training slice: {slice_name}, samples: {len(X_train)}\")\n",
    "\n",
    "                for learner in CONFIG.MODELS:\n",
    "                    model = learner[\"Estimator\"](**learner[\"params\"])\n",
    "                    model.fit(\n",
    "                        X_train,\n",
    "                        y_train,\n",
    "                        sample_weight=sw,\n",
    "                        eval_set=[(X_valid, y_valid)],\n",
    "                        verbose=False,\n",
    "                    )\n",
    "\n",
    "                    mask = valid_idx >= cutoff\n",
    "                    if mask.any():\n",
    "                        idxs = valid_idx[mask]\n",
    "                        oof_preds[learner[\"name\"]][slice_name][idxs] = model.predict(train_X[idxs])\n",
    "                    if cutoff > 0 and (~mask).any():\n",
    "                        oof_preds[learner[\"name\"]][slice_name][valid_idx[~mask]] = oof_preds[learner[\"name\"]][\"full_data\"][valid_idx[~mask]]\n",
    "\n",
    "                    test_preds[learner[\"name\"]][slice_name] += model.predict(test_X)\n",
    "\n",
    "        # Normalize test predictions\n",
    "        for learner_name in test_preds:\n",
    "            for slice_name in test_preds[learner_name]:\n",
    "                test_preds[learner_name][slice_name] /= CONFIG.N_FOLDS\n",
    "\n",
    "        return oof_preds, test_preds, model_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb723ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_and_submit(train_df, oof_preds, test_preds, submission_df):\n",
    "    learner_ensembles = {}\n",
    "    for learner_name in oof_preds:\n",
    "        scores = {s: pearsonr(train_df, oof_preds[learner_name][s])[0] for s in oof_preds[learner_name]}\n",
    "        total_score = sum(scores.values())\n",
    "\n",
    "        oof_simple = np.mean(list(oof_preds[learner_name].values()), axis=0)\n",
    "        test_simple = np.mean(list(test_preds[learner_name].values()), axis=0)\n",
    "        score_simple = pearsonr(train_df, oof_simple)[0]\n",
    "\n",
    "        oof_weighted = sum(\n",
    "            scores[s] / total_score * oof_preds[learner_name][s]\n",
    "            for s in scores  # type: ignore\n",
    "        )\n",
    "        test_weighted = sum(\n",
    "            scores[s] / total_score * test_preds[learner_name][s]\n",
    "            for s in scores  # type: ignore\n",
    "        )\n",
    "        score_weighted = pearsonr(train_df, oof_weighted)[0]\n",
    "\n",
    "        print(f\"\\n{learner_name.upper()} Simple Ensemble Pearson:   {score_simple:.4f}\")\n",
    "        print(f\"{learner_name.upper()} Weighted Ensemble Pearson: {score_weighted:.4f}\")\n",
    "\n",
    "        learner_ensembles[learner_name] = {\n",
    "            \"oof_simple\": oof_simple,\n",
    "            \"test_simple\": test_simple,\n",
    "        }\n",
    "\n",
    "    final_oof = np.mean([le[\"oof_simple\"] for le in learner_ensembles.values()], axis=0)\n",
    "    final_test = np.mean([le[\"test_simple\"] for le in learner_ensembles.values()], axis=0)\n",
    "    final_test = np.clip(final_test, CONFIG.CLIP_LOWER, CONFIG.CLIP_UPPER)\n",
    "    final_score = pearsonr(train_df, final_oof)[0]\n",
    "\n",
    "    print(f\"\\nFINAL ensemble across learners Pearson: {final_score:.4f}\")\n",
    "    submission_df = submission_df.with_columns(pl.Series(name=\"prediction\", values=final_test))\n",
    "    submission_df.write_csv(CONFIG.SUBMISSION_PATH)\n",
    "    print(\"Saved: submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2472b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting smart feature selection with 525886 samples...\n",
      "Using 525886 recent samples for feature selection\n",
      "Total features before selection: 926\n",
      "Removing low-variance and high-missing features...\n",
      "Features after variance/missing filter: 919\n",
      "Computing correlations...\n",
      "Computing mutual information...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing L1 regularization scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:1705: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.763e+00, tolerance: 8.097e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.709e+00, tolerance: 8.097e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.022e+01, tolerance: 8.097e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.214e+01, tolerance: 8.097e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.203e+01, tolerance: 8.097e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.436e+01, tolerance: 8.097e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.506e+01, tolerance: 8.097e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.541e+02, tolerance: 8.097e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.042e+02, tolerance: 8.097e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.365e+02, tolerance: 8.097e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.813e+02, tolerance: 8.097e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.231e+02, tolerance: 8.097e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.659e+02, tolerance: 8.097e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.020e+02, tolerance: 8.097e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.521e+01, tolerance: 8.097e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.680e+02, tolerance: 8.097e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.598e+02, tolerance: 8.097e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.429e+02, tolerance: 8.097e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.851e+02, tolerance: 8.097e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.423e+02, tolerance: 8.097e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.870e+02, tolerance: 8.097e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.036e+02, tolerance: 8.097e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.838e+02, tolerance: 8.097e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.261e+02, tolerance: 8.097e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.316e+02, tolerance: 8.097e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.519e+02, tolerance: 8.097e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.155e+03, tolerance: 8.097e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.383e+03, tolerance: 8.097e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.564e+03, tolerance: 8.097e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.335e+03, tolerance: 8.097e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.208e+03, tolerance: 8.097e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.618e+03, tolerance: 8.097e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.946e+03, tolerance: 8.097e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.838e+00, tolerance: 8.292e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.347e+00, tolerance: 8.292e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.170e+01, tolerance: 8.292e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.688e+00, tolerance: 8.292e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.336e+01, tolerance: 8.292e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.362e+01, tolerance: 8.292e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.075e+01, tolerance: 8.292e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.775e+01, tolerance: 8.292e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.046e+02, tolerance: 8.292e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.353e+02, tolerance: 8.292e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.990e+02, tolerance: 8.292e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.441e+02, tolerance: 8.292e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.328e+02, tolerance: 8.292e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.178e+02, tolerance: 8.292e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.743e+02, tolerance: 8.292e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.781e+02, tolerance: 8.292e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.225e+02, tolerance: 8.292e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.856e+02, tolerance: 8.292e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.758e+02, tolerance: 8.292e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.679e+02, tolerance: 8.292e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.741e+02, tolerance: 8.292e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.806e+02, tolerance: 8.292e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.213e+02, tolerance: 8.292e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.273e+02, tolerance: 8.292e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.224e+02, tolerance: 8.292e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.051e+03, tolerance: 8.292e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.437e+03, tolerance: 8.292e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.769e+03, tolerance: 8.292e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.194e+03, tolerance: 8.292e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.267e+03, tolerance: 8.292e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e+03, tolerance: 8.292e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.167e+03, tolerance: 8.292e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.537e+03, tolerance: 8.292e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.656e+00, tolerance: 8.306e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.451e+01, tolerance: 8.306e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.406e+01, tolerance: 8.306e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.062e+01, tolerance: 8.306e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.999e+00, tolerance: 8.306e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.381e+01, tolerance: 8.306e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.930e+01, tolerance: 8.306e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.372e+01, tolerance: 8.306e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.099e+01, tolerance: 8.306e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.069e+01, tolerance: 8.306e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.737e+01, tolerance: 8.306e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.527e+01, tolerance: 8.306e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.512e+01, tolerance: 8.306e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.137e+01, tolerance: 8.306e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.240e+02, tolerance: 8.306e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.910e+02, tolerance: 8.306e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.941e+02, tolerance: 8.306e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.769e+02, tolerance: 8.306e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.694e+02, tolerance: 8.306e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.969e+02, tolerance: 8.306e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.859e+02, tolerance: 8.306e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.036e+02, tolerance: 8.306e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.952e+02, tolerance: 8.306e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.992e+02, tolerance: 8.306e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.409e+02, tolerance: 8.306e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.487e+02, tolerance: 8.306e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.227e+02, tolerance: 8.306e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.450e+02, tolerance: 8.306e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.730e+02, tolerance: 8.306e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.644e+02, tolerance: 8.306e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.741e+02, tolerance: 8.306e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.238e+03, tolerance: 8.306e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.507e+03, tolerance: 8.306e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.995e+03, tolerance: 8.306e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.317e+03, tolerance: 8.306e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.685e+03, tolerance: 8.306e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.730e+03, tolerance: 8.306e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.185e+01, tolerance: 8.298e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.366e+01, tolerance: 8.298e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.133e+01, tolerance: 8.298e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.751e+01, tolerance: 8.298e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.382e+01, tolerance: 8.298e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.844e+01, tolerance: 8.298e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.725e+01, tolerance: 8.298e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.456e+02, tolerance: 8.298e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+02, tolerance: 8.298e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.064e+02, tolerance: 8.298e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.783e+02, tolerance: 8.298e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.657e+02, tolerance: 8.298e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.077e+02, tolerance: 8.298e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.033e+02, tolerance: 8.298e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.833e+02, tolerance: 8.298e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.682e+02, tolerance: 8.298e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.270e+02, tolerance: 8.298e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.432e+02, tolerance: 8.298e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.969e+02, tolerance: 8.298e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.373e+02, tolerance: 8.298e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.544e+02, tolerance: 8.298e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.713e+02, tolerance: 8.298e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.196e+03, tolerance: 8.298e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.545e+03, tolerance: 8.298e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.857e+03, tolerance: 8.298e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.054e+03, tolerance: 8.298e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.504e+03, tolerance: 8.298e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.809e+03, tolerance: 8.298e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.197e+03, tolerance: 8.298e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.111e+01, tolerance: 8.309e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.287e+01, tolerance: 8.309e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.873e+01, tolerance: 8.309e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.823e+01, tolerance: 8.309e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.760e+00, tolerance: 8.309e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.861e+01, tolerance: 8.309e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.688e+01, tolerance: 8.309e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.132e+01, tolerance: 8.309e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.618e+01, tolerance: 8.309e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.440e+02, tolerance: 8.309e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.204e+02, tolerance: 8.309e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.911e+02, tolerance: 8.309e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.305e+02, tolerance: 8.309e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.581e+02, tolerance: 8.309e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.271e+02, tolerance: 8.309e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.659e+02, tolerance: 8.309e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.353e+02, tolerance: 8.309e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.958e+02, tolerance: 8.309e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.353e+02, tolerance: 8.309e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.057e+02, tolerance: 8.309e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.253e+02, tolerance: 8.309e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.156e+02, tolerance: 8.309e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.369e+02, tolerance: 8.309e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.315e+02, tolerance: 8.309e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.157e+03, tolerance: 8.309e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.536e+03, tolerance: 8.309e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.824e+03, tolerance: 8.309e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.307e+03, tolerance: 8.309e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.445e+03, tolerance: 8.309e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.756e+03, tolerance: 8.309e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.013e+03, tolerance: 8.309e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.164e+03, tolerance: 8.309e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.323e+04, tolerance: 1.033e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing tree-based importance...\n",
      "Combining feature scores...\n",
      "Selected 120 features\n",
      "Top 10 selected features:\n",
      "   1. price_impact_trade_intensity_imb3 - Score: 92.2757\n",
      "   2. realized_spread_trade_intensity_imb3 - Score: 92.0876\n",
      "   3. effective_spread_trade_intensity_imb3 - Score: 91.7004\n",
      "   4. effective_spread_price_impact_imb3 - Score: 91.5065\n",
      "   5. kyle_lambda_vpin_imb3          - Score: 91.1313\n",
      "   6. realized_spread_trade_intensity_imb - Score: 90.9759\n",
      "   7. realized_spread_price_impact_imb - Score: 90.9257\n",
      "   8. realized_spread_price_impact_imb3 - Score: 90.7300\n",
      "   9. total_liquidity_liquidity_ratio_imb3 - Score: 90.6755\n",
      "  10. total_liquidity_liquidity_ratio_imb - Score: 90.5756\n",
      "Train data loaded with shape: (525886, 158)\n",
      "Test data loaded with shape: (538150, 158)\n"
     ]
    }
   ],
   "source": [
    "data = data_loader()\n",
    "train_X, train_y = data.train_X, data.train_y\n",
    "test = data.test_X\n",
    "\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c606ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONFIG.TRAIN:\n",
    "    run_stability = FEATURE_STABILITY(train_X, train_y, num_runs=5, importance_type=\"gain\")\n",
    "    run_stability.fit()\n",
    "    run_stability.summary_table.write_parquet(CONFIG.STABILITY_PATH)\n",
    "    run_stability.shap_df.write_parquet(CONFIG.SHAP_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e01b0143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fold 1/5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\envs\\edmund\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:34:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training slice: full_data, samples: 420708\n",
      "  Training slice: recent_95pct, samples: 420708\n",
      "  Training slice: recent_90pct, samples: 420708\n",
      "  Training slice: recent_85pct, samples: 420708\n",
      "  Training slice: recent_80pct, samples: 420708\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "  Training slice: full_data, samples: 420709\n",
      "  Training slice: recent_95pct, samples: 394415\n",
      "  Training slice: recent_90pct, samples: 368121\n",
      "  Training slice: recent_85pct, samples: 341827\n",
      "  Training slice: recent_80pct, samples: 315532\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "  Training slice: full_data, samples: 420709\n",
      "  Training slice: recent_95pct, samples: 394415\n",
      "  Training slice: recent_90pct, samples: 368121\n",
      "  Training slice: recent_85pct, samples: 341827\n",
      "  Training slice: recent_80pct, samples: 315532\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "  Training slice: full_data, samples: 420709\n",
      "  Training slice: recent_95pct, samples: 394415\n",
      "  Training slice: recent_90pct, samples: 368121\n",
      "  Training slice: recent_85pct, samples: 341827\n",
      "  Training slice: recent_80pct, samples: 315532\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "  Training slice: full_data, samples: 420709\n",
      "  Training slice: recent_95pct, samples: 394415\n",
      "  Training slice: recent_90pct, samples: 368121\n",
      "  Training slice: recent_85pct, samples: 341827\n",
      "  Training slice: recent_80pct, samples: 315532\n"
     ]
    }
   ],
   "source": [
    "eval = evaluate()\n",
    "oof_preds, test_preds, model_slices = eval.train_and_evaluate(train_X, train_y, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcbca010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGB Simple Ensemble Pearson:   0.1253\n",
      "XGB Weighted Ensemble Pearson: 0.1254\n",
      "\n",
      "FINAL ensemble across learners Pearson: 0.1253\n",
      "Saved: submission.csv\n"
     ]
    }
   ],
   "source": [
    "ensemble_and_submit(\n",
    "    train_y.to_numpy().flatten(),\n",
    "    oof_preds,\n",
    "    test_preds,\n",
    "    pl.DataFrame(\n",
    "        {\n",
    "            \"id\": [i for i in range(1, test.shape[0] + 1)],\n",
    "        }\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1c537ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X752': 0.13623877634277026,\n",
       " 'X757': 0.2997224471093961,\n",
       " 'X344': 0.3190095388067619,\n",
       " 'X759': 0.48866681888397734,\n",
       " 'X425': 0.575830740339469,\n",
       " 'X758': 0.6514685906339077,\n",
       " 'x_stat_median': 0.7804755071910973,\n",
       " 'X415': 1.0260118925728854,\n",
       " 'X508': 1.0482662609232827,\n",
       " 'X614': 1.3399310714035977,\n",
       " 'X444': 1.4136470736263924,\n",
       " 'X137': 1.777507570099907,\n",
       " 'X767': 1.8028083137708755,\n",
       " 'X766': 1.8594598319691076,\n",
       " 'X756': 1.8908012868520947,\n",
       " 'X751': 1.9402391779308832,\n",
       " 'X333': 2.0370406305211155,\n",
       " 'X570': 2.124013815188575,\n",
       " 'X608': 2.151968150568311,\n",
       " 'X27': 2.3103860849875324,\n",
       " 'X177': 2.4131049252443235,\n",
       " 'X421': 2.5918045435265915,\n",
       " 'X198': 2.861057463293814,\n",
       " 'X501': 3.00957472442429,\n",
       " 'X283': 3.1894961350318947,\n",
       " 'X191': 3.3148973062014497,\n",
       " 'X376': 3.3465444867325314,\n",
       " 'X343': 3.4826279560096642,\n",
       " 'X287': 3.6640958735957647,\n",
       " 'X419': 3.9382883445558567,\n",
       " 'X28': 4.169674604967346,\n",
       " 'X342': 4.327963175567005,\n",
       " 'X338': 4.471787847807335,\n",
       " 'X769': 4.752782542948813,\n",
       " 'X97': 4.7674330941656295,\n",
       " 'X40': 5.012934272740481,\n",
       " 'X98': 5.18201114965397,\n",
       " 'X613': 5.5240031325902015,\n",
       " 'X451': 5.597062184516016,\n",
       " 'X281': 5.7206217149897585,\n",
       " 'X427': 5.818419980279382,\n",
       " 'X772': 6.166119767126599,\n",
       " 'X331': 6.25062382622253,\n",
       " 'X778': 6.327239761672089,\n",
       " 'X768': 6.36088627354939,\n",
       " 'X22': 6.369034209757322,\n",
       " 'X345': 6.4506425298892065,\n",
       " 'X612': 6.453908103192263,\n",
       " 'X332': 6.455120271971684,\n",
       " 'X94': 6.522011122417203,\n",
       " 'X91': 6.5304243012840555,\n",
       " 'X750': 6.5855806751806805,\n",
       " 'X611': 6.599907198348753,\n",
       " 'X329': 6.791320369882615,\n",
       " 'X465': 6.868584981374688,\n",
       " 'X652': 6.974276550489332,\n",
       " 'X272': 7.181377801205756,\n",
       " 'X609': 7.410450705315557,\n",
       " 'X445': 7.507717596083993,\n",
       " 'X178': 7.561576134704495,\n",
       " 'X629': 7.572651660758363,\n",
       " 'X642': 7.811610891691779,\n",
       " 'X607': 8.16451514783875,\n",
       " 'X646': 8.421114794112775,\n",
       " 'X382': 8.89792719722112,\n",
       " 'X754': 9.07113144555112,\n",
       " 'X174': 9.34164547882273,\n",
       " 'X773': 9.411865684278276,\n",
       " 'X188': 9.728064252370837,\n",
       " 'X507': 9.871957165282181,\n",
       " 'X765': 10.399780363192868,\n",
       " 'X610': 10.448235762389357,\n",
       " 'X604': 10.453530282918374,\n",
       " 'X20': 10.55865836187546,\n",
       " 'X426': 10.635987535007258,\n",
       " 'X189': 10.659644344352307,\n",
       " 'X219': 10.698741929903814,\n",
       " 'X383': 10.72661344004549,\n",
       " 'X173': 10.755194048403213,\n",
       " 'X413': 10.786351098154727,\n",
       " 'X289': 10.89000299679367,\n",
       " 'X466': 10.958097873824515,\n",
       " 'X93': 10.982205959692648,\n",
       " 'X582': 11.098051881100261,\n",
       " 'X586': 11.233292989190433,\n",
       " 'X588': 11.285997462156724,\n",
       " 'X337': 11.65824491048928,\n",
       " 'X169': 11.726794107324222,\n",
       " 'X82': 11.795857729738277,\n",
       " 'X126': 11.96403367718129,\n",
       " 'X292': 12.037365854632304,\n",
       " 'X780': 12.165034017634248,\n",
       " 'X86': 12.314414105662618,\n",
       " 'X85': 12.320187653510152,\n",
       " 'X777': 12.337584308161418,\n",
       " 'X779': 12.382226715967976,\n",
       " 'X18': 12.412680656502335,\n",
       " 'X404': 12.730708913873782,\n",
       " 'X682': 12.858829889829273,\n",
       " 'X590': 13.004575769849938,\n",
       " 'X674': 13.166574443944468,\n",
       " 'X214': 13.238962261751494,\n",
       " 'X256': 13.260238175008668,\n",
       " 'X136': 13.268107408324852,\n",
       " 'X180': 13.271957846516813,\n",
       " 'X424': 13.29889287617298,\n",
       " 'X654': 13.483091752258193,\n",
       " 'X181': 13.52866663300279,\n",
       " 'X500': 13.599786425174795,\n",
       " 'X684': 13.694746820743136,\n",
       " 'X168': 13.72327783456038,\n",
       " 'X135': 13.752993401500696,\n",
       " 'X420': 13.799903913634571,\n",
       " 'X386': 13.947066226637578,\n",
       " 'X438': 14.007630454355198,\n",
       " 'X133': 14.050470528857513,\n",
       " 'X379': 14.054533056230667,\n",
       " 'X713': 14.193313784891554,\n",
       " 'X775': 14.227391236074167,\n",
       " 'X21': 14.308397480385013,\n",
       " 'X341': 14.321206468721924,\n",
       " 'X29': 14.359011977502421,\n",
       " 'X264': 14.411761906211574,\n",
       " 'X138': 14.555835473948719,\n",
       " 'X605': 14.674440192018597,\n",
       " 'X285': 14.683946959009484,\n",
       " 'X428': 15.007601871207136,\n",
       " 'X217': 15.04353107121017,\n",
       " 'X38': 15.254720941436982,\n",
       " 'X84': 15.425990385660688,\n",
       " 'X764': 15.453695776064036,\n",
       " 'X647': 15.489643667699191,\n",
       " 'X435': 15.653674704966502,\n",
       " 'X776': 15.681337996743023,\n",
       " 'X407': 15.784386642857296,\n",
       " 'X505': 15.945000324894982,\n",
       " 'X741': 15.956378318013988,\n",
       " 'X90': 16.04904556167186,\n",
       " 'X43': 16.14705676466644,\n",
       " 'X499': 16.17994811759733,\n",
       " 'X628': 16.209240969564753,\n",
       " 'X578': 16.21085064437162,\n",
       " 'X762': 16.300878151722575,\n",
       " 'X33': 16.564461367658634,\n",
       " 'X139': 16.749228939103226,\n",
       " 'X132': 16.88672379336698,\n",
       " 'X88': 17.015427284948082,\n",
       " 'X622': 17.41388624277389,\n",
       " 'X410': 17.48848844282856,\n",
       " 'X760': 17.49548648368459,\n",
       " 'X409': 17.505497925573867,\n",
       " 'X656': 17.51848794619965,\n",
       " 'X584': 17.628937738112793,\n",
       " 'X17': 17.64301776962456,\n",
       " 'X770': 17.77049382022281,\n",
       " 'X592': 17.770673481289744,\n",
       " 'x_stat_p25': 17.994859414716892,\n",
       " 'X205': 18.00189975319846,\n",
       " 'X269': 18.097199467862843,\n",
       " 'X576': 18.11993186361898,\n",
       " 'X32': 18.39322268018709,\n",
       " 'X384': 18.532151087250654,\n",
       " 'X416': 18.598745088092763,\n",
       " 'X464': 18.673403162859717,\n",
       " 'X589': 18.687638460664946,\n",
       " 'X602': 18.804641962327306,\n",
       " 'X96': 18.861244749533313,\n",
       " 'X303': 18.89261421839735,\n",
       " 'X655': 18.897744713598385,\n",
       " 'X336': 18.941218331916787,\n",
       " 'X44': 18.975742247528405,\n",
       " 'X42': 19.255178297768946,\n",
       " 'X37': 19.409365504046175,\n",
       " 'X385': 19.46885557606786,\n",
       " 'X414': 19.475247901541618,\n",
       " 'X587': 19.73604423820096,\n",
       " 'X282': 19.7457006493624,\n",
       " 'X727': 20.205483714653067,\n",
       " 'X131': 20.25189918300759,\n",
       " 'X561': 20.27291442015794,\n",
       " 'X24': 20.364184104520238,\n",
       " 'X368': 20.381717395723122,\n",
       " 'X335': 20.453118219968246,\n",
       " 'X77': 20.45394147013722,\n",
       " 'X443': 20.460205412254865,\n",
       " 'X179': 20.879965348901187,\n",
       " 'X378': 20.93167038316148,\n",
       " 'X166': 21.1756947972471,\n",
       " 'X377': 21.31244338193327,\n",
       " 'X326': 21.321637770160454,\n",
       " 'X581': 21.36606958072027,\n",
       " 'X606': 21.36813598423039,\n",
       " 'X710': 21.4359955317325,\n",
       " 'X371': 21.45549986314234,\n",
       " 'X753': 21.50875896155733,\n",
       " 'X175': 21.727506146490985,\n",
       " 'X650': 21.868807622262974,\n",
       " 'X436': 22.141658273443927,\n",
       " 'X95': 22.251491535217934,\n",
       " 'X163': 22.686832607779003,\n",
       " 'X130': 22.90814481340888,\n",
       " 'X422': 23.163176393957222,\n",
       " 'X197': 23.167472238802088,\n",
       " 'X730': 23.17059669412452,\n",
       " 'X294': 23.253283593710353,\n",
       " 'X92': 23.29490142383733,\n",
       " 'X458': 23.376563202047553,\n",
       " 'X218': 23.66530916865744,\n",
       " 'X678': 23.687640763978905,\n",
       " 'X284': 23.723397925263882,\n",
       " 'X591': 23.73413999005824,\n",
       " 'X296': 23.80618450519315,\n",
       " 'X731': 23.833553725036158,\n",
       " 'X167': 23.9761743984893,\n",
       " 'X564': 24.010103086161696,\n",
       " 'X579': 24.095150032392763,\n",
       " 'X291': 24.287529000411176,\n",
       " 'X339': 24.43375266123289,\n",
       " 'X140': 24.44427790789636,\n",
       " 'X298': 24.494225760385174,\n",
       " 'X323': 24.531018360685195,\n",
       " 'X683': 24.56474321873455,\n",
       " 'X39': 24.62238530263165,\n",
       " 'X125': 24.661155122720317,\n",
       " 'X35': 24.70698369894916,\n",
       " 'X216': 24.939385722671666,\n",
       " 'X127': 24.948220057155634,\n",
       " 'X627': 25.36519985055057,\n",
       " 'X675': 25.366395130425403,\n",
       " 'X572': 25.442614367362587,\n",
       " 'X375': 25.457979670790294,\n",
       " 'X463': 25.77662542572241,\n",
       " 'X651': 25.823651832382225,\n",
       " 'X585': 25.923568792398203,\n",
       " 'X498': 26.087381298560558,\n",
       " 'X186': 26.09879901658484,\n",
       " 'X583': 26.126515274347565,\n",
       " 'X279': 26.258915252644243,\n",
       " 'X302': 26.307884133993845,\n",
       " 'X617': 26.325909257534203,\n",
       " 'X418': 26.4287655677513,\n",
       " 'X580': 26.553972456836934,\n",
       " 'X739': 26.599452918867247,\n",
       " 'X738': 26.703880178662093,\n",
       " 'X124': 26.930609554877766,\n",
       " 'X340': 26.956162330495303,\n",
       " 'X46': 27.050304005715994,\n",
       " 'X278': 27.053155221685923,\n",
       " 'X563': 27.105074369677528,\n",
       " 'X679': 27.133719890504523,\n",
       " 'X432': 27.290549775409687,\n",
       " 'X558': 27.33239441122589,\n",
       " 'X271': 27.40833205184108,\n",
       " 'X472': 27.581577995796067,\n",
       " 'X204': 27.648454336983324,\n",
       " 'X577': 27.649688626866425,\n",
       " 'X370': 27.93238784366356,\n",
       " 'X735': 27.964511411906464,\n",
       " 'X324': 27.974377300328978,\n",
       " 'X567': 28.223534506440405,\n",
       " 'X569': 28.263125603770373,\n",
       " 'X626': 28.363795416166585,\n",
       " 'X601': 28.366514462763377,\n",
       " 'X374': 28.444305710949948,\n",
       " 'X172': 28.486116961735988,\n",
       " 'X277': 28.550563207717875,\n",
       " 'X450': 28.654468002675667,\n",
       " 'X557': 28.67175643191716,\n",
       " 'X648': 28.745033396435254,\n",
       " 'X160': 28.78701112004304,\n",
       " 'X31': 28.895558050748296,\n",
       " 'X222': 28.899621224165656,\n",
       " 'X761': 28.915947710830153,\n",
       " 'X380': 28.92325377093014,\n",
       " 'X328': 28.947141312506176,\n",
       " 'X120': 29.058410742278543,\n",
       " 'X680': 29.141699964997578,\n",
       " 'X763': 29.156572740571143,\n",
       " 'X506': 29.167937081943062,\n",
       " 'X83': 29.180439902863828,\n",
       " 'X30': 29.44549102122715,\n",
       " 'X566': 29.46423311461241,\n",
       " 'X330': 29.532639262567915,\n",
       " 'X643': 29.650191335312392,\n",
       " 'X546': 29.70544538332766,\n",
       " 'X603': 29.707313197113095,\n",
       " 'X270': 29.722028887420855,\n",
       " 'X49': 30.02060766494983,\n",
       " 'X685': 30.028986830686467,\n",
       " 'X553': 30.034540228461562,\n",
       " 'X712': 30.06435024212789,\n",
       " 'X452': 30.06951627149442,\n",
       " 'X9': 30.15827669410396,\n",
       " 'X774': 30.19637282552815,\n",
       " 'X560': 30.367793686138977,\n",
       " 'X226': 30.49411692840374,\n",
       " 'X373': 30.531630325371548,\n",
       " 'X297': 30.57210587658814,\n",
       " 'X225': 30.574037447776902,\n",
       " 'X325': 30.57878400136707,\n",
       " 'X327': 30.58239916308014,\n",
       " 'X215': 30.660697603619894,\n",
       " 'X25': 30.72014613999818,\n",
       " 'X473': 30.754014617319292,\n",
       " 'X80': 30.775593510466237,\n",
       " 'X212': 30.816519149331608,\n",
       " 'X702': 30.88866902571073,\n",
       " 'X431': 31.012518428335493,\n",
       " 'X15': 31.052221965273198,\n",
       " 'X484': 31.473709282427887,\n",
       " 'X734': 31.49632141228299,\n",
       " 'X367': 31.606583859890875,\n",
       " 'X290': 31.73110348446202,\n",
       " 'X23': 31.782886909999704,\n",
       " 'X387': 32.129249531199804,\n",
       " 'X437': 32.17260979333993,\n",
       " 'X726': 32.19861833707784,\n",
       " 'X89': 32.22016715395642,\n",
       " 'X362': 32.26198081331207,\n",
       " 'X157': 32.45707758056924,\n",
       " 'X740': 32.45756164264584,\n",
       " 'X571': 32.470227241788706,\n",
       " 'X293': 32.4829722931257,\n",
       " 'X372': 32.5079654321788,\n",
       " 'X442': 32.590401960025225,\n",
       " 'X575': 32.70347238334736,\n",
       " 'X711': 32.70882015174862,\n",
       " 'X568': 32.732673552022135,\n",
       " 'X79': 32.74551834300927,\n",
       " 'X288': 32.88948866146752,\n",
       " 'X286': 33.04680122896827,\n",
       " 'X51': 33.21398610343875,\n",
       " 'X41': 33.32760562060481,\n",
       " 'X55': 33.73645149198539,\n",
       " 'X299': 33.76282110004704,\n",
       " 'X48': 33.864319498324605,\n",
       " 'X165': 33.98006074804646,\n",
       " 'X677': 34.24615783011077,\n",
       " 'X45': 34.25532538285097,\n",
       " 'X547': 34.43276126154759,\n",
       " 'X706': 34.49938149126458,\n",
       " 'X573': 34.578110812509976,\n",
       " 'X449': 34.851932126933654,\n",
       " 'X487': 34.864339789773936,\n",
       " 'X623': 34.965769709054,\n",
       " 'X681': 35.0237463706561,\n",
       " 'X78': 35.04504336218366,\n",
       " 'X550': 35.10267918069686,\n",
       " 'X548': 35.17776360128567,\n",
       " 'X360': 35.20350728420237,\n",
       " 'X574': 35.28534162535709,\n",
       " 'X300': 35.53834241541816,\n",
       " 'X742': 35.67437167541587,\n",
       " 'X707': 35.796093708738795,\n",
       " 'x_stat_idx_max': 36.2100366029778,\n",
       " 'X676': 36.23347339301495,\n",
       " 'X334': 36.422640791561776,\n",
       " 'X565': 36.60381322974167,\n",
       " 'X171': 36.628541207747595,\n",
       " 'X134': 36.68648176601608,\n",
       " 'X559': 36.78552213961799,\n",
       " 'X457': 36.78851163337022,\n",
       " 'X238': 36.80708909921231,\n",
       " 'X47': 37.02652829211984,\n",
       " 'X56': 37.26711350024886,\n",
       " 'X743': 37.841664191160035,\n",
       " 'X295': 37.87855929271223,\n",
       " 'X320': 38.03773663781483,\n",
       " 'X301': 38.060263583152874,\n",
       " 'X185': 38.10742055742631,\n",
       " 'X638': 38.1334664996453,\n",
       " 'X221': 38.23304828621894,\n",
       " 'X653': 38.37624489750934,\n",
       " 'X162': 38.38437023965116,\n",
       " 'X196': 38.63123213613261,\n",
       " 'X552': 38.66000857764266,\n",
       " 'X50': 38.8410957351486,\n",
       " 'X366': 38.842014670186664,\n",
       " 'X461': 38.9924768546166,\n",
       " 'X494': 39.04920572748749,\n",
       " 'X709': 39.35100513475169,\n",
       " 'X644': 39.51537094151471,\n",
       " 'X462': 39.58142241595158,\n",
       " 'X322': 39.69138747077638,\n",
       " 'X36': 39.865599118575844,\n",
       " 'X119': 39.88030065283514,\n",
       " 'X471': 39.881168202507844,\n",
       " 'X363': 39.95679563004663,\n",
       " 'X68': 40.089808340522595,\n",
       " 'X398': 40.117964635411624,\n",
       " 'X247': 40.156691997875974,\n",
       " 'X621': 40.1954719131239,\n",
       " 'X121': 40.2342313801978,\n",
       " 'X549': 40.329678814866554,\n",
       " 'X600': 40.486077695049296,\n",
       " 'X280': 40.51246503732402,\n",
       " 'X554': 40.64309628026613,\n",
       " 'X703': 40.7092101868184,\n",
       " 'X321': 40.729337164202406,\n",
       " 'X480': 41.055897787557626,\n",
       " 'X190': 41.13175611298377,\n",
       " 'X224': 41.21793890626504,\n",
       " 'X555': 41.29192286910353,\n",
       " 'X625': 41.3682885648926,\n",
       " 'X74': 41.865289173249444,\n",
       " 'X670': 41.94130462164233,\n",
       " 'X401': 42.051173823462975,\n",
       " 'X114': 42.06453451823088,\n",
       " 'X537': 42.085840730722545,\n",
       " 'X599': 42.25832770452753,\n",
       " 'X459': 42.32354646444529,\n",
       " 'X211': 42.36914524982796,\n",
       " 'X744': 42.410961661061584,\n",
       " 'X736': 42.41918556121523,\n",
       " 'X19': 42.43577904350208,\n",
       " 'x_stat_mean': 42.63295072817547,\n",
       " 'X562': 42.65299124736548,\n",
       " 'X598': 42.65410942840453,\n",
       " 'X128': 42.70629630486096,\n",
       " 'X671': 42.731503819554916,\n",
       " 'X34': 42.87802090662137,\n",
       " 'X123': 42.883789899341636,\n",
       " 'X469': 42.91400558014615,\n",
       " 'X361': 42.999559454884434,\n",
       " 'X704': 43.00755419244538,\n",
       " 'X624': 43.05015774643394,\n",
       " 'X441': 43.093538906401676,\n",
       " 'X749': 43.245693907622815,\n",
       " 'X497': 43.270342352090125,\n",
       " 'X732': 43.39055159510751,\n",
       " 'X62': 43.409467765308364,\n",
       " 'X203': 43.504307619953074,\n",
       " 'X351': 43.51306268369388,\n",
       " 'X365': 43.54697926404312,\n",
       " 'X76': 43.656261835415926,\n",
       " 'X151': 43.79785728692438,\n",
       " 'x_stat_p75': 43.809794056329665,\n",
       " 'X268': 43.96067848427255,\n",
       " 'X645': 43.98208843364906,\n",
       " 'X708': 44.0499629366193,\n",
       " 'X357': 44.2794348479512,\n",
       " 'X71': 44.31917371224255,\n",
       " 'X556': 44.38908260719017,\n",
       " 'X156': 44.506668349382046,\n",
       " 'X129': 44.646579751235,\n",
       " 'X73': 44.66864177187893,\n",
       " 'X369': 44.75388384276812,\n",
       " 'X403': 44.896814202408116,\n",
       " 'X195': 44.929745274296,\n",
       " 'X52': 45.271371135095244,\n",
       " 'X356': 45.27506331495208,\n",
       " 'X699': 45.33362450960216,\n",
       " 'X276': 45.39390835982063,\n",
       " 'X161': 45.557840982388335,\n",
       " 'x_stat_std': 45.59059085724924,\n",
       " 'X267': 45.63454294780698,\n",
       " 'X470': 45.975295411662366,\n",
       " 'X154': 46.038848491373805,\n",
       " 'X54': 46.182869156913874,\n",
       " 'X657': 46.215895067163245,\n",
       " 'X53': 46.30193176241249,\n",
       " 'X477': 46.587537461742606,\n",
       " 'X240': 46.90357226864848,\n",
       " 'X479': 46.90737453569314,\n",
       " 'X262': 47.20761579734645,\n",
       " 'X1': 47.263139210840755,\n",
       " 'X318': 47.28629819940125,\n",
       " 'X223': 47.579479294493794,\n",
       " 'X187': 47.80996688104892,\n",
       " 'X476': 47.93534780158181,\n",
       " 'X634': 47.96208474061001,\n",
       " 'X536': 48.041808322601156,\n",
       " 'X115': 48.05212145517724,\n",
       " 'X698': 48.29077804415972,\n",
       " 'X429': 48.31857420165424,\n",
       " 'X118': 48.37872260703618,\n",
       " 'X696': 48.61499188763574,\n",
       " 'X263': 48.64787792807035,\n",
       " 'X408': 48.72193185508588,\n",
       " 'X456': 48.81372216759791,\n",
       " 'X319': 48.865178615075166,\n",
       " 'X412': 48.90334224934442,\n",
       " 'X504': 48.99856868539503,\n",
       " 'X540': 49.010306853708464,\n",
       " 'X530': 49.09372188612368,\n",
       " 'X618': 49.15311205122669,\n",
       " 'X538': 49.36361888733844,\n",
       " 'X434': 49.59188798573667,\n",
       " 'X695': 49.599985425352614,\n",
       " 'X183': 49.669290762219966,\n",
       " 'X545': 49.84506627508349,\n",
       " 'x_stat_above_mean_count': 49.98985972624253,\n",
       " 'X672': 50.00813390468594,\n",
       " 'X381': 50.109606872152014,\n",
       " 'X700': 50.18005790610317,\n",
       " 'X728': 50.19382833615448,\n",
       " 'X640': 50.60873232350371,\n",
       " 'X493': 50.61296173335918,\n",
       " 'X639': 50.76105935796108,\n",
       " 'x_stat_idx_min': 50.90373261415678,\n",
       " 'X16': 51.02717882183249,\n",
       " 'X26': 51.33818034825537,\n",
       " 'X619': 51.431009682155555,\n",
       " 'X402': 51.433209497097224,\n",
       " 'X447': 51.5052804013693,\n",
       " 'X355': 51.55659091623606,\n",
       " 'X67': 51.575153098694265,\n",
       " 'X87': 51.60398622343058,\n",
       " 'X737': 51.60431522443808,\n",
       " 'X635': 51.60545867903763,\n",
       " 'X524': 51.62483934018886,\n",
       " 'X150': 51.63656617252872,\n",
       " 'x_stat_range': 51.81817154757133,\n",
       " 'X455': 52.06351037966732,\n",
       " 'X72': 52.151056882270915,\n",
       " 'X620': 52.18684725389268,\n",
       " 'X723': 52.216320290296295,\n",
       " 'X597': 52.3721026230842,\n",
       " 'X246': 52.42269316034184,\n",
       " 'X673': 52.45125832154677,\n",
       " 'X533': 52.623543652453485,\n",
       " 'X113': 52.73810698968181,\n",
       " 'X478': 52.758875977520304,\n",
       " 'X543': 52.81854832785906,\n",
       " 'X108': 52.927350825864764,\n",
       " 'X275': 53.05043004114764,\n",
       " 'X317': 53.05216966255813,\n",
       " 'X239': 53.0971486915228,\n",
       " 'X649': 53.14375199532721,\n",
       " 'X525': 53.160093914066024,\n",
       " 'X448': 53.16786598902801,\n",
       " 'X112': 53.26459922502822,\n",
       " 'X724': 53.390685422533956,\n",
       " 'X486': 53.443651609827576,\n",
       " 'X595': 53.456452323726715,\n",
       " 'X641': 53.50805315482511,\n",
       " 'X551': 53.54059399693047,\n",
       " 'X155': 53.5743475304389,\n",
       " 'X535': 53.70575190153675,\n",
       " 'X468': 53.92910826481562,\n",
       " 'X544': 53.96765977835658,\n",
       " 'X313': 53.97428120434422,\n",
       " 'X245': 54.03643843872667,\n",
       " 'X705': 54.0515633571064,\n",
       " 'X314': 54.07592883326075,\n",
       " 'X315': 54.079396060592096,\n",
       " 'X667': 54.18781961064209,\n",
       " 'X70': 54.39782244014734,\n",
       " 'X440': 54.47656829270365,\n",
       " 'X213': 54.501298925313925,\n",
       " 'X194': 54.579176423722714,\n",
       " 'X261': 54.592234677784816,\n",
       " 'X666': 54.627011611313314,\n",
       " 'X232': 54.67438777261158,\n",
       " 'X534': 54.849867263089486,\n",
       " 'X233': 54.935102050581435,\n",
       " 'X159': 54.93957609250229,\n",
       " 'X145': 55.07622661821698,\n",
       " 'X122': 55.16349898484485,\n",
       " 'X771': 55.19074164612817,\n",
       " 'X541': 55.52793274356687,\n",
       " 'X359': 55.56240014075774,\n",
       " 'X184': 55.652549384110706,\n",
       " 'X148': 55.65266770479976,\n",
       " 'X496': 55.93798261136574,\n",
       " 'X248': 55.9482459121784,\n",
       " 'X104': 56.02275960113309,\n",
       " 'X354': 56.130489006444364,\n",
       " 'X312': 56.16672445543869,\n",
       " 'X348': 56.27248577350504,\n",
       " 'X14': 56.2942650296363,\n",
       " 'X542': 56.50565245382423,\n",
       " 'X668': 56.555864928474584,\n",
       " 'X202': 56.58471169832158,\n",
       " 'X64': 56.60847473798893,\n",
       " 'X109': 56.6813452737854,\n",
       " 'X110': 56.7106171711518,\n",
       " 'X453': 56.79031676465754,\n",
       " 'X509': 56.79980268157587,\n",
       " 'X503': 56.80671615520796,\n",
       " 'X65': 56.811657829876694,\n",
       " 'X430': 57.227547651454806,\n",
       " 'X417': 57.315976386557075,\n",
       " 'X116': 57.433281734895985,\n",
       " 'X397': 57.445063529556194,\n",
       " 'X433': 57.61167605447696,\n",
       " 'X210': 57.65500659143169,\n",
       " 'X396': 57.68194094206535,\n",
       " 'X755': 57.725341997749304,\n",
       " 'X81': 57.75273647722569,\n",
       " 'X230': 58.01622316258801,\n",
       " 'X117': 58.26124033528103,\n",
       " 'X523': 58.36923386768499,\n",
       " 'X390': 58.59209059199397,\n",
       " 'X512': 58.63986039718833,\n",
       " 'X209': 59.16950915497219,\n",
       " 'X406': 59.26302287459815,\n",
       " 'X439': 59.27979392410329,\n",
       " 'X231': 59.417322951073515,\n",
       " 'X201': 59.51799796589526,\n",
       " 'X745': 59.53806689775225,\n",
       " 'X454': 59.591042030046204,\n",
       " 'X13': 59.7035246398802,\n",
       " 'X521': 59.74090398969766,\n",
       " 'X260': 59.74959104023689,\n",
       " 'X350': 59.77276675868595,\n",
       " 'X208': 59.90533221129689,\n",
       " 'X2': 60.02990981459952,\n",
       " 'X59': 60.039792636802616,\n",
       " 'X358': 60.141206534527164,\n",
       " 'X106': 60.14971312144922,\n",
       " 'X596': 60.317145125552756,\n",
       " 'X12': 60.357106441214285,\n",
       " 'X229': 60.48010163649952,\n",
       " 'X66': 60.48938946096411,\n",
       " 'X392': 60.503241633332706,\n",
       " 'X594': 60.58158974858252,\n",
       " 'X149': 60.68050610255011,\n",
       " 'X531': 60.72171703603786,\n",
       " 'X701': 60.92150211506091,\n",
       " 'X539': 60.95609306514831,\n",
       " 'X75': 60.962653628066825,\n",
       " 'X636': 61.04863054691352,\n",
       " 'X353': 61.189217212647556,\n",
       " 'X747': 61.189256263239294,\n",
       " 'X722': 61.191921855735536,\n",
       " 'X101': 61.32380389321063,\n",
       " 'X529': 61.33740338024837,\n",
       " 'X485': 61.345208259411486,\n",
       " 'X193': 61.37059145238024,\n",
       " 'X395': 61.453492262612365,\n",
       " 'X748': 61.51242399959672,\n",
       " 'X746': 61.526104234709386,\n",
       " 'X733': 61.5559523935326,\n",
       " 'X316': 61.61670045614266,\n",
       " 'X475': 61.69895671642805,\n",
       " 'X349': 61.73136180405103,\n",
       " 'X107': 61.860980708042455,\n",
       " 'X259': 61.893496857590904,\n",
       " 'X200': 61.95597725376266,\n",
       " 'X615': 62.038445765827134,\n",
       " 'X63': 62.060352846009195,\n",
       " 'X669': 62.23459068043457,\n",
       " 'X460': 62.38381474467801,\n",
       " 'X400': 62.577480190261205,\n",
       " 'X266': 62.602483337905795,\n",
       " 'X492': 62.60592147919227,\n",
       " 'X729': 62.80363721391978,\n",
       " 'X690': 62.808787192651344,\n",
       " 'X719': 62.84165272904565,\n",
       " 'X11': 63.01343333739348,\n",
       " 'X522': 63.017368111995445,\n",
       " 'X411': 63.06236359653699,\n",
       " 'X244': 63.158255446074314,\n",
       " 'X491': 63.261266797883884,\n",
       " 'X153': 63.33495609058616,\n",
       " 'X526': 63.358244911269985,\n",
       " 'X364': 63.394577010765154,\n",
       " 'X691': 63.47647062171479,\n",
       " 'X393': 63.50150615150901,\n",
       " 'X694': 63.58955537992034,\n",
       " 'X405': 63.59846607891434,\n",
       " 'X307': 63.62008181843123,\n",
       " 'X309': 63.67489065741081,\n",
       " 'X664': 63.698159772577355,\n",
       " 'X502': 63.935428140699464,\n",
       " 'X102': 64.05275308526552,\n",
       " 'X692': 64.20475082675024,\n",
       " 'X3': 64.21675669746539,\n",
       " 'X103': 64.47857302319437,\n",
       " 'X144': 64.74801019711929,\n",
       " 'X237': 64.93375554586237,\n",
       " 'X662': 65.0028110688544,\n",
       " 'X718': 65.19564417699969,\n",
       " 'X352': 65.26304897079545,\n",
       " 'X616': 65.32938002449352,\n",
       " 'X170': 65.44040685220565,\n",
       " 'X311': 65.4655588691028,\n",
       " 'X274': 65.50050267601252,\n",
       " 'X61': 65.77405687056907,\n",
       " 'X192': 65.94081258335063,\n",
       " 'X182': 65.9802731854232,\n",
       " 'X143': 66.06886175858472,\n",
       " 'X528': 66.09808469094915,\n",
       " 'X100': 66.16462054811909,\n",
       " 'X258': 66.209189097276,\n",
       " 'X394': 66.37636803846674,\n",
       " 'X446': 66.40881668033352,\n",
       " 'X273': 66.48173420259597,\n",
       " 'X265': 66.49631266547131,\n",
       " 'X58': 66.5421120039423,\n",
       " 'X714': 66.54867516625148,\n",
       " 'X725': 66.64675176532455,\n",
       " 'X518': 66.6469018433379,\n",
       " 'X391': 66.66093912347195,\n",
       " 'X697': 66.72521756991092,\n",
       " 'X251': 66.73215829609708,\n",
       " 'X146': 67.20532604539984,\n",
       " 'X10': 67.23833312761883,\n",
       " 'X495': 67.25549554873415,\n",
       " 'X207': 67.26092931161138,\n",
       " 'X308': 67.31409814073983,\n",
       " 'X4': 67.32941445229758,\n",
       " 'X423': 67.39708521668456,\n",
       " 'X5': 67.45468578704458,\n",
       " 'X69': 67.4891698938129,\n",
       " 'X663': 67.64756449493791,\n",
       " 'X593': 67.66507199784694,\n",
       " 'X111': 67.67483968050841,\n",
       " 'X399': 67.69202394436867,\n",
       " 'X6': 67.73283233602876,\n",
       " 'X306': 67.74790057114029,\n",
       " 'X176': 67.94893934186896,\n",
       " 'X8': 68.05265510338835,\n",
       " 'X147': 68.06446139218569,\n",
       " 'X254': 68.07414467680987,\n",
       " 'X164': 68.14116706210656,\n",
       " 'X532': 68.26177724729556,\n",
       " 'buy_qty': 68.47490907062618,\n",
       " 'X152': 68.47779407145791,\n",
       " 'X228': 68.50152538286298,\n",
       " 'X255': 68.52725758615112,\n",
       " 'X220': 68.5834721708471,\n",
       " 'X60': 68.59481682274468,\n",
       " 'X637': 68.77177589778228,\n",
       " 'X142': 68.82252294791809,\n",
       " 'X7': 68.83759477641321,\n",
       " 'X467': 68.89652376264036,\n",
       " 'X658': 68.9591180367974,\n",
       " 'X347': 68.95949195952961,\n",
       " 'X511': 69.0939547496023,\n",
       " 'X659': 69.13881691488022,\n",
       " 'X346': 69.21172480003288,\n",
       " 'X227': 69.25771757793068,\n",
       " 'X389': 69.34952305801582,\n",
       " 'X527': 69.41074647338984,\n",
       " 'X310': 69.69538102707139,\n",
       " 'X57': 69.8070650292354,\n",
       " 'X105': 69.84488141720223,\n",
       " 'X665': 69.85580298209143,\n",
       " 'X252': 70.05734528077375,\n",
       " 'X630': 70.1936575895361,\n",
       " 'X632': 70.26243244557841,\n",
       " 'X660': 70.30787397513929,\n",
       " 'X206': 70.46031126024737,\n",
       " 'X99': 70.60536898224906,\n",
       " 'X141': 70.76064180399617,\n",
       " 'X513': 70.88487470078161,\n",
       " 'X519': 70.9455474303855,\n",
       " 'X199': 71.10939240394323,\n",
       " 'X517': 71.14237572210288,\n",
       " 'X720': 71.16608194185251,\n",
       " 'X482': 71.2688744737835,\n",
       " 'X510': 71.29775508520869,\n",
       " 'X693': 71.3886673329893,\n",
       " 'X249': 71.53738301305205,\n",
       " 'X305': 71.58320315307321,\n",
       " 'X257': 71.63506271168741,\n",
       " 'X388': 71.87032081732181,\n",
       " 'X236': 72.003667972338,\n",
       " 'X250': 72.01902015905324,\n",
       " 'X516': 72.11802125000055,\n",
       " 'X158': 72.2490338289809,\n",
       " 'X631': 72.34403140475837,\n",
       " 'X490': 72.41137709453669,\n",
       " 'X483': 72.4611074996192,\n",
       " 'X253': 72.48764748929518,\n",
       " 'X514': 72.49086058202538,\n",
       " 'X243': 72.70316319638147,\n",
       " 'X688': 72.83270833805365,\n",
       " 'X515': 72.87240258342989,\n",
       " 'X686': 72.92552679691865,\n",
       " 'X241': 72.93811551831841,\n",
       " 'X687': 73.05973978158062,\n",
       " 'X716': 73.43039935028006,\n",
       " 'X474': 73.43876449948701,\n",
       " 'X481': 73.44482824682032,\n",
       " 'X633': 73.47026592375566,\n",
       " 'X235': 73.49858721732932,\n",
       " 'X242': 73.55562606858906,\n",
       " 'X234': 73.69601513325163,\n",
       " 'sell_qty': 74.22214527425692,\n",
       " 'X304': 74.39037766065246,\n",
       " 'X689': 74.50286536800324,\n",
       " 'trade_intensity': 74.51129648953285,\n",
       " 'X721': 74.73790598748154,\n",
       " 'volume': 75.00351132995738,\n",
       " 'X661': 75.28736091120666,\n",
       " 'bid_qty_ask_qty_buy_qty_imb2': 75.60709131539227,\n",
       " 'X520': 75.84594000122605,\n",
       " 'X488': 75.99888284703104,\n",
       " 'X489': 76.0061622435245,\n",
       " 'bid_qty': 76.71736577881461,\n",
       " 'X715': 76.97868754876441,\n",
       " 'buy_sell_qty_spread': 77.25313159235283,\n",
       " 'X717': 77.25434837415335,\n",
       " 'buy_sell_qty_ratio': 77.75869888607697,\n",
       " 'log_buy_qty': 77.83793968112387,\n",
       " 'log_sell_qty': 78.2293338051044,\n",
       " 'buy_sell_volume': 78.62750198335931,\n",
       " 'bid_ask_qty_ratio': 78.69783551546881,\n",
       " 'bid_ask_qty_spread': 78.83697124525715,\n",
       " 'ask_qty': 78.85335015672014,\n",
       " 'effective_spread': 79.12339946415428,\n",
       " 'bid_ask_to_volume_ratio': 79.21267799921667,\n",
       " 'bid_ask_to_buy_sell_qty_ratio': 80.05492613058752,\n",
       " 'log_bid_qty': 80.18651268752934,\n",
       " 'bid_qty_ask_qty_sell_qty_imb2': 80.28305080033077,\n",
       " 'buy_sell_imbalance': 80.29680534589099,\n",
       " 'log_ask_qty': 80.30359248872159,\n",
       " 'selling_pressure': 80.50134715546379,\n",
       " 'bid_qty_sell_qty_imb': 81.0433108087528,\n",
       " 'bid_ask_volume': 81.17229794665428,\n",
       " 'bid_ask_spread': 81.21256065199866,\n",
       " 'buy_sell_volume_bid_ask_to_volume_ratio_buy_sell_to_volume_ratio_imb2': 81.33230692334362,\n",
       " 'bid_qty_buy_qty_imb': 81.41072303036681,\n",
       " 'buy_sell_to_volume_ratio': 81.44020593381106,\n",
       " 'vpin': 81.60633790934821,\n",
       " 'ask_qty_sell_qty_imb': 81.78772620237048,\n",
       " 'bid_ask_ratio': 81.82182812346612,\n",
       " 'bid_ask_volume_buy_sell_volume_bid_ask_to_volume_ratio_imb2': 81.83904441667565,\n",
       " 'liquidity_ratio': 81.90812584637892,\n",
       " 'buy_sell_ratio': 81.92250600585825,\n",
       " 'kyle_lambda': 81.99088662393393,\n",
       " 'order_flow_imbalance': 82.02138257478016,\n",
       " 'buying_pressure': 82.12115815286523,\n",
       " 'buy_sell_volume_bid_ask_to_volume_ratio_imb': 82.17605753668917,\n",
       " 'log_volume': 82.25193460395722,\n",
       " 'net_pressure': 82.30916176963659,\n",
       " 'total_liquidity': 82.41229554197058,\n",
       " 'liquidity_imbalance': 82.50954871982523,\n",
       " 'bid_qty_volume_imb3': 82.59890800930944,\n",
       " 'ask_qty_volume_imb': 82.60025310739971,\n",
       " 'price_impact': 82.8106923208801,\n",
       " 'sqrt_volume': 82.82023866804184,\n",
       " 'ask_qty_buy_qty_imb': 82.89282392095096,\n",
       " 'bid_qty_buy_qty_imb3': 83.11365110673192,\n",
       " 'bid_qty_buy_qty_sell_qty_imb2': 83.13180549844411,\n",
       " 'realized_spread': 83.15911832898115,\n",
       " 'bid_qty_ask_qty_volume_imb2': 83.35308120311502,\n",
       " 'bid_qty_sell_qty_imb3': 83.39168096414974,\n",
       " 'bid_qty_ask_qty_imb': 83.41602558097185,\n",
       " 'bid_qty_ask_qty_imb3': 83.51600721203106,\n",
       " 'bid_qty_volume_imb': 83.99138019669711,\n",
       " 'ask_qty_buy_qty_imb3': 84.27226159501555,\n",
       " 'bid_ask_volume_buy_sell_volume_buy_sell_to_volume_ratio_imb2': 84.35937190649476,\n",
       " 'ask_qty_sell_qty_imb3': 84.4577122242466,\n",
       " 'bid_ask_ratio_buy_sell_ratio_order_flow_imbalance_imb2': 84.59078244042291,\n",
       " 'buy_sell_ratio_order_flow_imbalance_imb3': 84.6184513979698,\n",
       " 'ask_qty_volume_imb3': 84.64366005551905,\n",
       " 'buy_qty_sell_qty_imb': 84.73898692384411,\n",
       " 'bid_ask_spread_buy_sell_ratio_imb': 84.79724523593076,\n",
       " 'buy_qty_sell_qty_imb3': 84.83908252767759,\n",
       " 'buy_qty_volume_imb': 84.93731590974562,\n",
       " 'bid_ask_qty_ratio_bid_ask_qty_spread_imb': 84.99805877870486,\n",
       " 'buy_qty_volume_imb3': 85.03715831150815,\n",
       " 'bid_ask_qty_ratio_bid_ask_qty_spread_imb3': 85.08018829991563,\n",
       " 'sell_qty_volume_imb': 85.13811767934975,\n",
       " 'sell_qty_volume_imb3': 85.23716810074542,\n",
       " 'buy_sell_qty_ratio_buy_sell_qty_spread_imb': 85.26991708732331,\n",
       " 'bid_ask_spread_bid_ask_ratio_imb': 85.30047050426559,\n",
       " 'ask_qty_buy_qty_volume_imb2': 85.31225667734257,\n",
       " 'bid_ask_ratio_order_flow_imbalance_imb3': 85.32400174563067,\n",
       " 'bid_ask_spread_buy_sell_ratio_order_flow_imbalance_imb2': 85.38434319509875,\n",
       " 'ask_qty_sell_qty_volume_imb2': 85.499750605486,\n",
       " 'bid_ask_volume_bid_ask_to_volume_ratio_imb': 85.54538650995391,\n",
       " 'bid_qty_buy_qty_volume_imb2': 85.64413775410023,\n",
       " 'bid_ask_ratio_order_flow_imbalance_imb': 85.67705441785314,\n",
       " 'bid_qty_sell_qty_volume_imb2': 85.74525113506118,\n",
       " 'effective_spread_realized_spread_trade_intensity_imb2': 85.7554176182148,\n",
       " 'ask_qty_buy_qty_sell_qty_imb2': 85.84018357673253,\n",
       " 'bid_ask_volume_bid_ask_to_volume_ratio_buy_sell_to_volume_ratio_imb2': 85.89257225500499,\n",
       " 'bid_ask_spread_order_flow_imbalance_imb3': 85.97235738072948,\n",
       " 'buy_qty_sell_qty_volume_imb2': 86.13374261539536,\n",
       " 'bid_ask_spread_order_flow_imbalance_imb': 86.45628893077253,\n",
       " 'bid_ask_volume_buy_sell_volume_imb': 86.62131818669322,\n",
       " 'bid_ask_volume_buy_sell_volume_imb3': 86.71913597128935,\n",
       " 'bid_ask_spread_bid_ask_ratio_buy_sell_ratio_imb2': 86.92914636295438,\n",
       " 'bid_ask_volume_buy_sell_to_volume_ratio_imb': 87.00824814370468,\n",
       " 'total_liquidity_liquidity_imbalance_imb': 87.16311612034566,\n",
       " 'bid_ask_to_buy_sell_qty_ratio_buy_sell_imbalance_imb': 87.3830960130876,\n",
       " 'buy_sell_volume_buy_sell_to_volume_ratio_imb': 87.39185460868653,\n",
       " 'effective_spread_price_impact_trade_intensity_imb2': 87.58165308293201,\n",
       " 'liquidity_imbalance_liquidity_ratio_imb3': 87.58495399368378,\n",
       " 'bid_ask_to_volume_ratio_buy_sell_to_volume_ratio_imb': 87.59398446355374,\n",
       " 'buying_pressure_net_pressure_imb3': 87.67332187929797,\n",
       " 'buy_sell_ratio_order_flow_imbalance_imb': 87.67386915279953,\n",
       " 'effective_spread_realized_spread_price_impact_imb2': 87.8665763562348,\n",
       " 'bid_ask_spread_buy_sell_ratio_imb3': 87.94271796878135,\n",
       " 'bid_ask_ratio_buy_sell_ratio_imb': 88.15008738684296,\n",
       " 'total_liquidity_liquidity_imbalance_liquidity_ratio_imb2': 88.24926249772189,\n",
       " 'bid_ask_spread_bid_ask_ratio_imb3': 88.38885643898263,\n",
       " 'kyle_lambda_vpin_imb': 88.61994468413499,\n",
       " 'bid_ask_spread_bid_ask_ratio_order_flow_imbalance_imb2': 88.70459950386987,\n",
       " 'buying_pressure_selling_pressure_net_pressure_imb2': 88.72910935102357,\n",
       " 'bid_ask_ratio_buy_sell_ratio_imb3': 88.93208094269289,\n",
       " 'price_impact_trade_intensity_imb': 88.9445844019206,\n",
       " 'realized_spread_price_impact_trade_intensity_imb2': 89.03111605844816,\n",
       " 'effective_spread_price_impact_imb': 89.59756214400916,\n",
       " 'effective_spread_realized_spread_imb3': 89.6361033172087,\n",
       " 'buying_pressure_selling_pressure_imb': 89.7051617676812,\n",
       " 'total_liquidity_liquidity_imbalance_imb3': 89.72689693116378,\n",
       " 'buying_pressure_selling_pressure_imb3': 89.80624372706663,\n",
       " 'effective_spread_trade_intensity_imb': 89.8150508620034,\n",
       " 'buying_pressure_net_pressure_imb': 89.9053488988677,\n",
       " 'liquidity_imbalance_liquidity_ratio_imb': 89.969669652127,\n",
       " 'selling_pressure_net_pressure_imb': 90.09494549339814,\n",
       " 'effective_spread_realized_spread_imb': 90.17924646677464,\n",
       " 'selling_pressure_net_pressure_imb3': 90.19332689452328,\n",
       " 'total_liquidity_liquidity_ratio_imb': 90.57558734825115,\n",
       " 'total_liquidity_liquidity_ratio_imb3': 90.67549766519609,\n",
       " 'realized_spread_price_impact_imb3': 90.72998472463001,\n",
       " 'realized_spread_price_impact_imb': 90.9257094131351,\n",
       " 'realized_spread_trade_intensity_imb': 90.97588812544942,\n",
       " 'kyle_lambda_vpin_imb3': 91.13133268449332,\n",
       " 'effective_spread_price_impact_imb3': 91.50653802104512,\n",
       " 'effective_spread_trade_intensity_imb3': 91.70041781070867,\n",
       " 'realized_spread_trade_intensity_imb3': 92.08758399151176,\n",
       " 'price_impact_trade_intensity_imb3': 92.27574978246581}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(sorted(CONFIG.COMBINED_SCORES.items(), key=lambda item: item[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edmund",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
