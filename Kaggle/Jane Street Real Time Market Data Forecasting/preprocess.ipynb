{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(f\"Memory usage of dataframe is {start_mem:.2f} MB\")\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if (\n",
    "                    c_min > np.finfo(np.float16).min\n",
    "                    and c_max < np.finfo(np.float16).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif (\n",
    "                    c_min > np.finfo(np.float32).min\n",
    "                    and c_max < np.finfo(np.float32).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(f\"Memory usage after optimization is: {end_mem:.2f} MB\")\n",
    "    decrease = 100 * (start_mem - end_mem) / start_mem\n",
    "    print(f\"Decreased by {decrease:.2f}%\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"responder_6\"\n",
    "main = f\"C:/Users/edmun/OneDrive/Desktop/Personal-Projects/Kaggle/Jane Street Real Time Market Data Forecasting/\"\n",
    "\n",
    "# Number of dates to skip from the beginning of the dataset\n",
    "skip_dates = 500\n",
    "\n",
    "# Define the feature names based on the number of features (79 in this case)\n",
    "feature_names = [f\"feature_{i:02d}\" for i in range(79)]\n",
    "exogeneous_features = [\n",
    "    \"sin_time_id\",\n",
    "    \"cos_time_id\",\n",
    "    \"sin_time_id_halfday\",\n",
    "    \"cos_time_id_halfday\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 654.51 MB\n",
      "Memory usage after optimization is: 335.60 MB\n",
      "Decreased by 48.73%\n",
      "Memory usage of dataframe is 944.04 MB\n",
      "Memory usage after optimization is: 484.06 MB\n",
      "Decreased by 48.73%\n",
      "Memory usage of dataframe is 1022.35 MB\n",
      "Memory usage after optimization is: 524.21 MB\n",
      "Decreased by 48.73%\n",
      "Memory usage of dataframe is 1352.24 MB\n",
      "Memory usage after optimization is: 693.36 MB\n",
      "Decreased by 48.73%\n",
      "Memory usage of dataframe is 1690.96 MB\n",
      "Memory usage after optimization is: 867.04 MB\n",
      "Decreased by 48.73%\n",
      "Memory usage of dataframe is 1800.46 MB\n",
      "Memory usage after optimization is: 923.18 MB\n",
      "Decreased by 48.73%\n",
      "Memory usage of dataframe is 2088.53 MB\n",
      "Memory usage after optimization is: 1070.89 MB\n",
      "Decreased by 48.73%\n",
      "Memory usage of dataframe is 2132.85 MB\n",
      "Memory usage after optimization is: 1093.61 MB\n",
      "Decreased by 48.73%\n",
      "Memory usage of dataframe is 2067.02 MB\n",
      "Memory usage after optimization is: 1059.86 MB\n",
      "Decreased by 48.73%\n",
      "Memory usage of dataframe is 2112.32 MB\n",
      "Memory usage after optimization is: 1083.09 MB\n",
      "Decreased by 48.73%\n"
     ]
    }
   ],
   "source": [
    "full = []\n",
    "for i in range(10):\n",
    "    t0 = (\n",
    "        pd.read_parquet(f\"{main}/data/train.parquet/partition_id={i}/part-0.parquet\")\n",
    "        .fillna(0)\n",
    "        .set_index(\"date_id\")\n",
    "    )\n",
    "    full.append(reduce_mem_usage(t0))\n",
    "\n",
    "full = pd.concat(full)\n",
    "\n",
    "full[\"sin_time_id\"] = np.sin(2 * np.pi * full[\"time_id\"] / 967)\n",
    "full[\"cos_time_id\"] = np.cos(2 * np.pi * full[\"time_id\"] / 967)\n",
    "full[\"sin_time_id_halfday\"] = np.sin(2 * np.pi * full[\"time_id\"] / 483)\n",
    "full[\"cos_time_id_halfday\"] = np.cos(2 * np.pi * full[\"time_id\"] / 483)\n",
    "\n",
    "full = full[full.index >= skip_dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of validation dates to use\n",
    "num_valid_dates = 100\n",
    "\n",
    "# Number of folds for cross-validation\n",
    "N_fold = 5\n",
    "\n",
    "dates = full.index.unique()\n",
    "\n",
    "# Define validation dates as the last `num_valid_dates` dates\n",
    "valid_dates = dates[-num_valid_dates:]\n",
    "\n",
    "# Define training dates as all dates except the last `num_valid_dates` dates\n",
    "train_dates = dates[:-num_valid_dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = full[feature_names + exogeneous_features]\n",
    "Y = full[[target]]\n",
    "weight = full[[\"weight\"]]\n",
    "\n",
    "del full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_train():\n",
    "    X_valid = X[X.index.isin(valid_dates)]\n",
    "    y_valid = Y[Y.index.isin(valid_dates)]\n",
    "    w_valid = weight[weight.index.isin(valid_dates)]\n",
    "\n",
    "    X_valid.to_parquet(f\"{main}/data/training_data/X_valid.parquet\")\n",
    "    y_valid.to_parquet(f\"{main}/data/training_data/y_valid.parquet\")\n",
    "    w_valid.to_parquet(f\"{main}/data/training_data/w_valid.parquet\")\n",
    "\n",
    "    for fold in range(N_fold):\n",
    "        selected_dates = [\n",
    "            date for ii, date in enumerate(train_dates) if ii % N_fold != fold\n",
    "        ]\n",
    "        X_train = X[X.index.isin(selected_dates)]\n",
    "        y_train = Y[Y.index.isin(selected_dates)]\n",
    "        w_train = weight[weight.index.isin(selected_dates)]\n",
    "\n",
    "        X_train.to_parquet(f\"{main}/data/training_data/X_train_{fold}.parquet\")\n",
    "        y_train.to_parquet(f\"{main}/data/training_data/y_train_{fold}.parquet\")\n",
    "        w_train.to_parquet(f\"{main}/data/training_data/w_train_{fold}.parquet\")\n",
    "\n",
    "        del X_train, y_train, w_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
